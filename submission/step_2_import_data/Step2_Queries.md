# Step 2 Import Data queries

### Query 1

**Query string**: `azure`

**Index**: courses

**Results**:

```json
{
  "@odata.context": "https://corporate-training-search.search.windows.net/indexes('courses-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 5.3410544,
      "Key": "ms-learn21933bf9-68d3-4649-b58a-79fbb476be02",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure",
      "rating_average": 0,
      "rating_count": 0,
      "role": "developer",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.3410544,
      "Key": "ms-learn360412d8-4f79-4219-acc3-6d5e2134d880",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure",
      "rating_average": 0,
      "rating_count": 0,
      "role": "devops-engineer",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.3410544,
      "Key": "ms-learn4c970879-187f-473c-83d5-986109db3183",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure",
      "rating_average": 0,
      "rating_count": 0,
      "role": "administrator",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.3410544,
      "Key": "ms-learnc9f624d0-f2ec-49c8-bcb2-c89b79b051d2",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure",
      "rating_average": 0,
      "rating_count": 0,
      "role": "solution-architect",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.26932,
      "Key": "ms-learn1769801f-ea93-456d-afe4-06dc019e8f71",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "solution-architect",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.26932,
      "Key": "ms-learn56bc8c78-fa2b-4b59-9daa-ba89721ce27c",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "administrator",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.26932,
      "Key": "ms-learn76dcb4e7-6c94-4ed5-93e8-8ec05ce9b86b",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "developer",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.26932,
      "Key": "ms-learn89c14ed4-e008-400d-baac-0549e8299b57",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "devops-engineer",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.1762805,
      "Key": "ms-learn48efecbf-9b8c-47a5-aa46-deea3294ab25",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-devops",
      "rating_average": 0,
      "rating_count": 0,
      "role": "administrator",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.1762805,
      "Key": "ms-learnf394c98b-a99f-4225-aa77-152294025ebd",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-devops",
      "rating_average": 0,
      "rating_count": 0,
      "role": "solution-architect",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.1762805,
      "Key": "ms-learnf41794e0-2585-4036-9237-05f74b61d6b0",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-devops",
      "rating_average": 0,
      "rating_count": 0,
      "role": "developer",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.1762805,
      "Key": "ms-learnf41e6014-6251-40f2-85c5-03baed68b755",
      "description": "Provision databases in Azure Pipelines",
      "duration": 62,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-devops",
      "rating_average": 0,
      "rating_count": 0,
      "role": "devops-engineer",
      "source": "MS Learn",
      "title": "Provision databases in Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/provision-database-azure-pipelines/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Provision databases",
        "Azure Pipelines"
      ]
    },
    {
      "@search.score": 5.171188,
      "Key": "ms-learndb69aa91-d4da-48f9-a77c-5603bcae3596",
      "description": "Discover Azure portal and Azure DevOps tools that help you quickly and efficiently define and scale up load tests for apps.",
      "duration": 54,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.63,
      "rating_count": 147,
      "role": "developer",
      "source": "MS Learn",
      "title": "Load test Azure web apps by using Azure DevOps",
      "url": "https://docs.microsoft.com/en-us/learn/modules/load-test-web-app-azure-devops/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure DevOps tools",
        "Azure portal",
        "load tests",
        "apps"
      ]
    },
    {
      "@search.score": 5.104546,
      "Key": "ms-learn3b2eceda-f984-4440-804d-c18cce4d3653",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure-devops",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "solution-architect",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.104546,
      "Key": "ms-learn7682ab16-a067-41b8-9188-b8c4f433cec6",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure-devops",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "devops-engineer",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.104546,
      "Key": "ms-learnae8e2557-daa0-4f90-bafd-d80ba94675c0",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure-devops",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "developer",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.104546,
      "Key": "ms-learnf05da97a-a2dd-4dcc-8018-c9826fb2b0dd",
      "description": "Implement a CI/CD pipeline for Azure Functions.",
      "duration": 46,
      "instructor": "",
      "level": "beginner",
      "product": "azure-devops",
      "rating_average": 4.69,
      "rating_count": 378,
      "role": "administrator",
      "source": "MS Learn",
      "title": "Automate Azure Functions deployments with Azure Pipelines",
      "url": "https://docs.microsoft.com/en-us/learn/modules/deploy-azure-functions/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "CI/CD pipeline",
        "Azure Functions"
      ]
    },
    {
      "@search.score": 5.0844913,
      "Key": "ms-learn3f5306a1-2460-4628-9ada-8f0628b20bbd",
      "description": "Monitor models with Azure Machine Learning",
      "duration": 39,
      "instructor": "",
      "level": "intermediate",
      "product": "azure",
      "rating_average": 4.75,
      "rating_count": 504,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Monitor models with Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-models-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "models"
      ]
    },
    {
      "@search.score": 5.0844913,
      "Key": "ms-learn5de4bb8a-9063-4a38-adb6-4d8f6f0c12b1",
      "description": "Work with Data in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.66,
      "rating_count": 1119,
      "role": "student",
      "source": "MS Learn",
      "title": "Work with Data in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/work-with-data-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Data"
      ]
    },
    {
      "@search.score": 5.0844913,
      "Key": "ms-learn7dfc1bb4-abe2-4277-a732-162f1b38b412",
      "description": "Work with Compute in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.68,
      "rating_count": 992,
      "role": "student",
      "source": "MS Learn",
      "title": "Work with Compute in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/use-compute-contexts-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Compute"
      ]
    },
    {
      "@search.score": 5.0844913,
      "Key": "ms-learn81d1ec7d-958f-4e0f-9607-9ec1344b67ab",
      "description": "Work with Compute in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.68,
      "rating_count": 992,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Work with Compute in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/use-compute-contexts-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Compute"
      ]
    },
    {
      "@search.score": 5.0844913,
      "Key": "ms-learna274e897-5b2e-4ff3-aec9-2066e94d9a51",
      "description": "Work with Data in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.66,
      "rating_count": 1119,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Work with Data in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/work-with-data-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Data"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn0479d887-32ce-477b-b184-9230e096562a",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn25b613a7-0afa-46dc-be9a-3b34c30a1d40",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn3e93d44c-8438-46e8-a157-15a2dfa6c6ca",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn64fe0253-71fd-4c27-b288-6e8cf819d02c",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn7a84294d-d64c-4fa9-afb8-6f99822c848e",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn7be24452-07d1-4acc-99b3-89b901049505",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn843d6d18-cb80-417e-932e-206e15c80b57",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learn88c9641b-7fc9-4791-9798-fc047ba013a5",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learnbdb45f14-e397-40ab-bf99-d3ff1cc0ea43",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learncb1e0a98-cce5-45a9-810e-c6e147a777f2",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learncf9fbb13-4097-4c66-9cc9-582abfcc7298",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 5.0018287,
      "Key": "ms-learnefcdc4e3-d588-4b25-b109-65b7c593572b",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.9685764,
      "Key": "ms-learn59c58efa-d830-4c65-8ac4-5432bb0ec73e",
      "description": "Introduction to the Azure Machine Learning SDK",
      "duration": 60,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.65,
      "rating_count": 2869,
      "role": "student",
      "source": "MS Learn",
      "title": "Introduction to the Azure Machine Learning SDK",
      "url": "https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning SDK",
        "Introduction"
      ]
    },
    {
      "@search.score": 4.9685764,
      "Key": "ms-learn6456b6d8-0af1-4dfd-b895-37ecfb3df42b",
      "description": "Introduction to the Azure Machine Learning SDK",
      "duration": 60,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.65,
      "rating_count": 2869,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Introduction to the Azure Machine Learning SDK",
      "url": "https://docs.microsoft.com/en-us/learn/modules/intro-to-azure-machine-learning-service/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning SDK",
        "Introduction"
      ]
    },
    {
      "@search.score": 4.9685764,
      "Key": "ms-learn94a8abf2-6e37-40ed-8fed-6c23d50a7424",
      "description": "Monitor data drift with Azure Machine Learning",
      "duration": 42,
      "instructor": "",
      "level": "intermediate",
      "product": "azure",
      "rating_average": 4.8,
      "rating_count": 814,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Monitor data drift with Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-data-drift-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "data drift"
      ]
    },
    {
      "@search.score": 4.9685764,
      "Key": "ms-learn9e2bd51e-0f26-487b-b828-4bd6fd850743",
      "description": "Tune hyperparameters with Azure Machine Learning",
      "duration": 46,
      "instructor": "",
      "level": "intermediate",
      "product": "azure",
      "rating_average": 4.76,
      "rating_count": 544,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Tune hyperparameters with Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/tune-hyperparameters-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Tune hyperparameters"
      ]
    },
    {
      "@search.score": 4.9197173,
      "Key": "ms-learn181bbcf0-6713-4ee7-b858-3cf54674ed18",
      "description": "Monitor models with Azure Machine Learning",
      "duration": 39,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-portal",
      "rating_average": 4.75,
      "rating_count": 504,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Monitor models with Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-models-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "models"
      ]
    },
    {
      "@search.score": 4.9197173,
      "Key": "ms-learnd6417f73-e2e0-4eba-8996-bcda8666a60b",
      "description": "Implement CI/CD with Azure DevOps",
      "duration": 28,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-databricks",
      "rating_average": 4.74,
      "rating_count": 141,
      "role": "data-engineer",
      "source": "MS Learn",
      "title": "Implement CI/CD with Azure DevOps",
      "url": "https://docs.microsoft.com/en-us/learn/modules/implement-ci-cd-azure-devops/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure DevOps",
        "CI/CD"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learn13f442b0-f1d1-4402-8c3e-13f0c8b6ce8d",
      "description": "Create an Azure Cognitive Search solution",
      "duration": 63,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-cognitive-search",
      "rating_average": 4.91,
      "rating_count": 45,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Create an Azure Cognitive Search solution",
      "url": "https://docs.microsoft.com/en-us/learn/modules/create-azure-cognitive-search-solution/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Cognitive Search solution"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learn4ffb7ba0-0771-4a01-9da7-915635fb6ba4",
      "description": "Monitor models with Azure Machine Learning",
      "duration": 39,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-machine-learning",
      "rating_average": 4.75,
      "rating_count": 504,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Monitor models with Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-models-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "models"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learn683814dd-934d-4e72-a5fd-81a3c8037999",
      "description": "Create an Azure Cognitive Search solution",
      "duration": 63,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-cognitive-search",
      "rating_average": 4.91,
      "rating_count": 45,
      "role": "developer",
      "source": "MS Learn",
      "title": "Create an Azure Cognitive Search solution",
      "url": "https://docs.microsoft.com/en-us/learn/modules/create-azure-cognitive-search-solution/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Cognitive Search solution"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learn6b32e048-d4a8-426c-abf7-956369670549",
      "description": "Work with Compute in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.68,
      "rating_count": 992,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Work with Compute in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/use-compute-contexts-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Compute"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learna5b5e7fc-04c9-44a6-8f6d-2ffe764516c9",
      "description": "Work with Data in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.66,
      "rating_count": 1119,
      "role": "student",
      "source": "MS Learn",
      "title": "Work with Data in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/work-with-data-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Data"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learnacbba05d-493a-4548-a5df-ecf3ba1c7a05",
      "description": "Work with Data in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.66,
      "rating_count": 1119,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Work with Data in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/work-with-data-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Data"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learnbf5af1d1-1929-4291-ad51-1e521d19255d",
      "description": "Work with Compute in Azure Machine Learning",
      "duration": 45,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.68,
      "rating_count": 992,
      "role": "student",
      "source": "MS Learn",
      "title": "Work with Compute in Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/use-compute-contexts-in-aml/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Compute"
      ]
    },
    {
      "@search.score": 4.8391395,
      "Key": "ms-learne00a9b7f-cd37-41b1-87d3-d87018dcf606",
      "description": "Create an Azure Cognitive Search solution",
      "duration": 63,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-cognitive-search",
      "rating_average": 4.91,
      "rating_count": 45,
      "role": "solution-architect",
      "source": "MS Learn",
      "title": "Create an Azure Cognitive Search solution",
      "url": "https://docs.microsoft.com/en-us/learn/modules/create-azure-cognitive-search-solution/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Cognitive Search solution"
      ]
    },
    {
      "@search.score": 4.8038025,
      "Key": "ms-learn16681c04-f885-49d8-ab7e-e477936a6bdc",
      "description": "Tune hyperparameters with Azure Machine Learning",
      "duration": 46,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-portal",
      "rating_average": 4.76,
      "rating_count": 544,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Tune hyperparameters with Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/tune-hyperparameters-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "Tune hyperparameters"
      ]
    },
    {
      "@search.score": 4.8038025,
      "Key": "ms-learna5ffe016-69df-4be9-be9a-76bdfc4092c2",
      "description": "Monitor data drift with Azure Machine Learning",
      "duration": 42,
      "instructor": "",
      "level": "intermediate",
      "product": "azure-portal",
      "rating_average": 4.8,
      "rating_count": 814,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Monitor data drift with Azure Machine Learning",
      "url": "https://docs.microsoft.com/en-us/learn/modules/monitor-data-drift-with-azure-machine-learning/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Azure Machine Learning",
        "data drift"
      ]
    }
  ],
  "@odata.nextLink": "https://corporate-training-search.search.windows.net/indexes('courses-index')/docs?api-version=2021-04-30-Preview&search=azure&$skip=50"
}
```

---

### Query 2

**Query string**: `ai`

**Index**: courses

**Results**:

```json
{
  "@odata.context": "https://corporate-training-search.search.windows.net/indexes('courses-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 7.578247,
      "Key": "ms-learn359e902e-9270-42de-9687-536b9fe0164c",
      "description": "Learn about AI Builder licensing and how to buy and manage your AI Builder licenses.",
      "duration": 40,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.59,
      "rating_count": 17,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder licensing",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-licensing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder licensing",
        "AI Builder licenses"
      ]
    },
    {
      "@search.score": 7.578247,
      "Key": "ms-learnba340cd7-5db3-42f8-bdd7-036a6974f5f1",
      "description": "Learn about AI Builder licensing and how to buy and manage your AI Builder licenses.",
      "duration": 40,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.59,
      "rating_count": 17,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder licensing",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-licensing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder licensing",
        "AI Builder licenses"
      ]
    },
    {
      "@search.score": 7.299131,
      "Key": "ms-learna2d21ed4-31d6-4069-b772-3a50bcd65abe",
      "description": "Learn how to manage models in AI Builder.",
      "duration": 17,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.79,
      "rating_count": 1871,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Manage models in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/manage-models/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder",
        "models"
      ]
    },
    {
      "@search.score": 7.299131,
      "Key": "ms-learnf3ccfdbb-0235-4a74-9df4-477e8addff66",
      "description": "Learn how to manage models in AI Builder.",
      "duration": 17,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.79,
      "rating_count": 1871,
      "role": "maker",
      "source": "MS Learn",
      "title": "Manage models in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/manage-models/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder",
        "models"
      ]
    },
    {
      "@search.score": 6.9175625,
      "Key": "ms-learn7be24452-07d1-4acc-99b3-89b901049505",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 6.9175625,
      "Key": "ms-learnbdb45f14-e397-40ab-bf99-d3ff1cc0ea43",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 6.9175625,
      "Key": "ms-learnefcdc4e3-d588-4b25-b109-65b7c593572b",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 6.685671,
      "Key": "ms-learna2535dbf-ec97-4265-a26b-5b5c0aa689c3",
      "description": "Learn the basics of AI Builder Object detection and how it can benefit your organization.",
      "duration": 25,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.73,
      "rating_count": 147,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder Object detection",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-object-detection/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Object detection",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.685671,
      "Key": "ms-learnba849c68-1b7c-475d-8ea9-a9e255411450",
      "description": "Learn the basics of AI Builder Object detection and how it can benefit your organization.",
      "duration": 25,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.73,
      "rating_count": 147,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder Object detection",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-object-detection/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Object detection",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.505104,
      "Key": "ms-learn0197c8c6-dfc4-450b-9fa7-3f610977cc79",
      "description": "Learn about AI Builder Text recognition and how to use it with other Power Platform products.",
      "duration": 55,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.61,
      "rating_count": 197,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder Text recognition",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-text-recognition/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Text recognition",
        "other Power Platform products"
      ]
    },
    {
      "@search.score": 6.505104,
      "Key": "ms-learn15e073b4-6de0-4d11-b12a-32d65151d584",
      "description": "Learn about AI Builder Sentiment analysis and how to use it with other Power Platform products.",
      "duration": 55,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.65,
      "rating_count": 170,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder Sentiment analysis",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-sentiment-analysis/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Sentiment analysis",
        "other Power Platform products"
      ]
    },
    {
      "@search.score": 6.505104,
      "Key": "ms-learn2adf55dd-65ba-4833-976a-c6452dd7a775",
      "description": "Explore AI Builder Language detection and learn how to use it with other Power Platform products.",
      "duration": 27,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.63,
      "rating_count": 139,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder Language detection",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-language-detection/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Language detection",
        "other Power Platform products"
      ]
    },
    {
      "@search.score": 6.505104,
      "Key": "ms-learn73883ec6-3887-45a6-a027-bc9f2892392b",
      "description": "Learn about AI Builder Text recognition and how to use it with other Power Platform products.",
      "duration": 55,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.61,
      "rating_count": 197,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder Text recognition",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-text-recognition/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Text recognition",
        "other Power Platform products"
      ]
    },
    {
      "@search.score": 6.505104,
      "Key": "ms-learnd56b0c83-5e61-466a-972b-b95682fcfeb2",
      "description": "Explore AI Builder Language detection and learn how to use it with other Power Platform products.",
      "duration": 27,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.63,
      "rating_count": 139,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder Language detection",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-language-detection/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Language detection",
        "other Power Platform products"
      ]
    },
    {
      "@search.score": 6.505104,
      "Key": "ms-learnfc2cc759-b7e1-4d52-82f4-c26e23404919",
      "description": "Learn about AI Builder Sentiment analysis and how to use it with other Power Platform products.",
      "duration": 55,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.65,
      "rating_count": 170,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder Sentiment analysis",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-sentiment-analysis/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Sentiment analysis",
        "other Power Platform products"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learn13636881-10bb-406c-a7a0-4e77a1e37d5a",
      "description": "Learn the basics of invoice processing in AI Builder and how it can benefit your organization.",
      "duration": 10,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.81,
      "rating_count": 21,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with invoice processing in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/ai-builder-invoice-processing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "invoice processing",
        "AI Builder",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learn2f945536-a4a5-4c71-983d-717dba1a40c6",
      "description": "Learn the basics of receipt processing in AI Builder and how it can benefit your organization.",
      "duration": 12,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.79,
      "rating_count": 208,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with receipt processing in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/ai-builder-receipt-processing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "receipt processing",
        "AI Builder",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learn538855b9-afd9-4877-8730-2f93256b0ad2",
      "description": "Learn the basics of receipt processing in AI Builder and how it can benefit your organization.",
      "duration": 12,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.79,
      "rating_count": 208,
      "role": "administrator",
      "source": "MS Learn",
      "title": "Get started with receipt processing in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/ai-builder-receipt-processing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "receipt processing",
        "AI Builder",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learna07d9a53-b36f-4746-a8d5-c31995655667",
      "description": "Learn the basics of Form processing in AI Builder and how it can benefit your organization.",
      "duration": 37,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.74,
      "rating_count": 283,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with Form processing in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-form-processing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Form processing",
        "AI Builder",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learnb1ba00e9-49f3-4fb0-8cba-d67a7d207f84",
      "description": "Learn how to use Ai Builder Text Recognition to automate the tracking of shipments.",
      "duration": 108,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.8,
      "rating_count": 10,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Apply AI Builder Text Recognition in the transportation industry",
      "url": "https://docs.microsoft.com/en-us/learn/modules/apply-ai-builder-text-recognition-transportation-industry/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Ai Builder Text Recognition",
        "tracking",
        "shipments"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learnb4303e0a-a9ba-4900-a370-4ff2f1e43ba0",
      "description": "Learn how to use Ai Builder Text Recognition to automate the tracking of shipments.",
      "duration": 108,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.8,
      "rating_count": 10,
      "role": "maker",
      "source": "MS Learn",
      "title": "Apply AI Builder Text Recognition in the transportation industry",
      "url": "https://docs.microsoft.com/en-us/learn/modules/apply-ai-builder-text-recognition-transportation-industry/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Ai Builder Text Recognition",
        "tracking",
        "shipments"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learndb01cedc-7617-4aca-920c-076952a53cf2",
      "description": "Learn the basics of Form processing in AI Builder and how it can benefit your organization.",
      "duration": 37,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.74,
      "rating_count": 283,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with Form processing in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-form-processing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Form processing",
        "AI Builder",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.4864683,
      "Key": "ms-learnfd9c0ab6-fac1-4786-9d9e-319d219af5ee",
      "description": "Learn the basics of invoice processing in AI Builder and how it can benefit your organization.",
      "duration": 10,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.81,
      "rating_count": 21,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with invoice processing in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/ai-builder-invoice-processing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "invoice processing",
        "AI Builder",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.375618,
      "Key": "ms-learn11a560e9-d107-4229-8b6b-f99cf3c4920b",
      "description": "This self-paced module helps you build an AI model from the beginning and shows how you can use it in your business without writing a single line of code.",
      "duration": 30,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.75,
      "rating_count": 1744,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI model",
        "single line",
        "beginning",
        "business",
        "code"
      ]
    },
    {
      "@search.score": 6.375618,
      "Key": "ms-learn2b006004-9810-4dd1-9232-694e89f5510d",
      "description": "This self-paced module helps you build an AI model from the beginning and shows how you can use it in your business without writing a single line of code.",
      "duration": 30,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.75,
      "rating_count": 1744,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI model",
        "single line",
        "beginning",
        "business",
        "code"
      ]
    },
    {
      "@search.score": 6.372794,
      "Key": "ms-learn683b3d6c-a177-4384-a4cb-6f461202de0e",
      "description": "Learn the basics of AI Builder usage in Microsoft Power Automate and how it can benefit your organization. ",
      "duration": 60,
      "instructor": "",
      "level": "intermediate",
      "product": "ai-builder",
      "rating_average": 4.71,
      "rating_count": 702,
      "role": "maker",
      "source": "MS Learn",
      "title": "Use AI Builder in Power Automate",
      "url": "https://docs.microsoft.com/en-us/learn/modules/ai-builder-power-automate/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder usage",
        "Microsoft Power Automate",
        "basics",
        "organization"
      ]
    },
    {
      "@search.score": 6.372794,
      "Key": "ms-learna2cadb41-c6a9-4c0a-a9df-6054df03bd5f",
      "description": "Explore the AI Builder Key phrase extraction model and learn how to use it with other Power Platform products.",
      "duration": 52,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.67,
      "rating_count": 178,
      "role": "maker",
      "source": "MS Learn",
      "title": "Introduction to AI Builder Key phrase extraction",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-key-phrase-extraction/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Key phrase extraction model",
        "other Power Platform products",
        "AI Builder"
      ]
    },
    {
      "@search.score": 6.372794,
      "Key": "ms-learneedc2427-1be9-4593-8c65-a135f852ddff",
      "description": "Explore the AI Builder Key phrase extraction model and learn how to use it with other Power Platform products.",
      "duration": 52,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.67,
      "rating_count": 178,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Introduction to AI Builder Key phrase extraction",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-key-phrase-extraction/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Key phrase extraction model",
        "other Power Platform products",
        "AI Builder"
      ]
    },
    {
      "@search.score": 6.1735916,
      "Key": "ms-learn1545c987-7064-4af9-b056-b1e0c2669385",
      "description": "Learn about AI Builder Business card reader and how to use it in Microsoft Power Apps and Power Automate.",
      "duration": 90,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.62,
      "rating_count": 157,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder Business card reader",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-business-card-reader/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Business card reader",
        "Microsoft Power Apps",
        "Power Automate"
      ]
    },
    {
      "@search.score": 6.1735916,
      "Key": "ms-learnc824b6bc-d668-4efd-91c2-2a3009532fe4",
      "description": "Learn about AI Builder Business card reader and how to use it in Microsoft Power Apps and Power Automate.",
      "duration": 90,
      "instructor": "",
      "level": "beginner",
      "product": "ai-builder",
      "rating_average": 4.62,
      "rating_count": 157,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder Business card reader",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-business-card-reader/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder Business card reader",
        "Microsoft Power Apps",
        "Power Automate"
      ]
    },
    {
      "@search.score": 5.9804277,
      "Key": "ms-learn7d70effe-470c-403c-98f4-dd0295dab8a8",
      "description": "This module provides an overview of Azure AI and demonstrates how Microsoft tools, services, and infrastructure can help make AI real for your organization, whether you want to unlock insights from your latent data with knowledge mining, develop your own AI models with machine learning, or build immersive apps using AI.",
      "duration": 59,
      "instructor": "",
      "level": "beginner",
      "product": "azure",
      "rating_average": 4.75,
      "rating_count": 4523,
      "role": "ai-engineer",
      "source": "MS Learn",
      "title": "Microsoft Azure Artificial Intelligence (AI) strategy and solutions",
      "url": "https://docs.microsoft.com/en-us/learn/modules/azure-artificial-intelligence/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "Microsoft tools",
        "latent data",
        "knowledge mining",
        "machine learning",
        "immersive apps",
        "Azure AI",
        "AI models",
        "module",
        "overview",
        "services",
        "infrastructure",
        "organization",
        "insights"
      ]
    },
    {
      "@search.score": 5.8345456,
      "Key": "ms-learnd3f4bc2b-5846-48e4-9b03-f150459e1aff",
      "description": "Implement robotic process automation with Microsoft Power Automate, Teams, desktop flow, and AI Builder",
      "duration": 34,
      "instructor": "",
      "level": "intermediate",
      "product": "ai-builder",
      "rating_average": 4.73,
      "rating_count": 721,
      "role": "maker",
      "source": "MS Learn",
      "title": "Implement robotic process automation with Microsoft Power Automate, Teams, desktop flow, and AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/implement-power-automate-ui-flows-ai-builder/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "robotic process automation",
        "Microsoft Power Automate",
        "desktop flow",
        "AI Builder",
        "Teams"
      ]
    },
    {
      "@search.score": 4.722124,
      "Key": "ms-learn6dd898da-510e-4a47-8387-660b784ddc36",
      "description": "Learn about AI Builder licensing and how to buy and manage your AI Builder licenses.",
      "duration": 40,
      "instructor": "",
      "level": "beginner",
      "product": "power-platform",
      "rating_average": 4.59,
      "rating_count": 17,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder licensing",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-licensing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder licensing",
        "AI Builder licenses"
      ]
    },
    {
      "@search.score": 4.722124,
      "Key": "ms-learn6ff468c4-fc48-4772-aaa7-134d115937a2",
      "description": "Learn about AI Builder licensing and how to buy and manage your AI Builder licenses.",
      "duration": 40,
      "instructor": "",
      "level": "beginner",
      "product": "power-platform",
      "rating_average": 4.59,
      "rating_count": 17,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder licensing",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-licensing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder licensing",
        "AI Builder licenses"
      ]
    },
    {
      "@search.score": 4.722124,
      "Key": "ms-learnb1a36b89-28cc-41ae-92a6-846d53ad5e63",
      "description": "Learn about AI Builder licensing and how to buy and manage your AI Builder licenses.",
      "duration": 40,
      "instructor": "",
      "level": "beginner",
      "product": "power-automate",
      "rating_average": 4.59,
      "rating_count": 17,
      "role": "maker",
      "source": "MS Learn",
      "title": "Get started with AI Builder licensing",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-licensing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder licensing",
        "AI Builder licenses"
      ]
    },
    {
      "@search.score": 4.722124,
      "Key": "ms-learnd12854e2-c412-47e9-96bb-7414e13055dd",
      "description": "Learn about AI Builder licensing and how to buy and manage your AI Builder licenses.",
      "duration": 40,
      "instructor": "",
      "level": "beginner",
      "product": "power-automate",
      "rating_average": 4.59,
      "rating_count": 17,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Get started with AI Builder licensing",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-with-ai-builder-licensing/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder licensing",
        "AI Builder licenses"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learn0479d887-32ce-477b-b184-9230e096562a",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learn25b613a7-0afa-46dc-be9a-3b34c30a1d40",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learn3e93d44c-8438-46e8-a157-15a2dfa6c6ca",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learn64fe0253-71fd-4c27-b288-6e8cf819d02c",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learn7a84294d-d64c-4fa9-afb8-6f99822c848e",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "developer",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learn843d6d18-cb80-417e-932e-206e15c80b57",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-machine-learning",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learn88c9641b-7fc9-4791-9798-fc047ba013a5",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "student",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learncb1e0a98-cce5-45a9-810e-c6e147a777f2",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-cognitive-services",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.5846567,
      "Key": "ms-learncf9fbb13-4097-4c66-9cc9-582abfcc7298",
      "description": "Get started with AI on Azure",
      "duration": 34,
      "instructor": "",
      "level": "beginner",
      "product": "azure-bot-service",
      "rating_average": 4.78,
      "rating_count": 10997,
      "role": "data-scientist",
      "source": "MS Learn",
      "title": "Get started with AI on Azure",
      "url": "https://docs.microsoft.com/en-us/learn/modules/get-started-ai-fundamentals/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI",
        "Azure"
      ]
    },
    {
      "@search.score": 4.4540453,
      "Key": "company-moodle6b5d3f55-eb02-499d-9775-2e0e25659e07",
      "description": "Learn our company's Principles for the Responsible Use of AI",
      "duration": 1,
      "instructor": "Eileen Diaz",
      "level": "intermediate",
      "product": "NA",
      "rating_average": 4.3,
      "rating_count": 24,
      "role": "architect",
      "source": "Company Moodle",
      "title": "Ethics in AI",
      "url": "https://www.example.com/course12",
      "keyphrases": [
        "Responsible Use",
        "company",
        "Principles",
        "AI"
      ]
    },
    {
      "@search.score": 4.4430075,
      "Key": "ms-learn4c5d860b-a264-4177-857d-140e5f35a94f",
      "description": "Learn how to manage models in AI Builder.",
      "duration": 17,
      "instructor": "",
      "level": "beginner",
      "product": "power-platform",
      "rating_average": 4.79,
      "rating_count": 1871,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Manage models in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/manage-models/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder",
        "models"
      ]
    },
    {
      "@search.score": 4.4430075,
      "Key": "ms-learn508d1443-82ef-46d8-a03a-91b34e4a025a",
      "description": "Learn how to manage models in AI Builder.",
      "duration": 17,
      "instructor": "",
      "level": "beginner",
      "product": "power-automate",
      "rating_average": 4.79,
      "rating_count": 1871,
      "role": "business-user",
      "source": "MS Learn",
      "title": "Manage models in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/manage-models/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder",
        "models"
      ]
    },
    {
      "@search.score": 4.4430075,
      "Key": "ms-learn90e7c1da-89f6-45ff-bfc1-b04e3d12236e",
      "description": "Learn how to manage models in AI Builder.",
      "duration": 17,
      "instructor": "",
      "level": "beginner",
      "product": "power-automate",
      "rating_average": 4.79,
      "rating_count": 1871,
      "role": "maker",
      "source": "MS Learn",
      "title": "Manage models in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/manage-models/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder",
        "models"
      ]
    },
    {
      "@search.score": 4.4430075,
      "Key": "ms-learne4482286-4af9-4301-8131-5044e327ba73",
      "description": "Learn how to manage models in AI Builder.",
      "duration": 17,
      "instructor": "",
      "level": "beginner",
      "product": "power-platform",
      "rating_average": 4.79,
      "rating_count": 1871,
      "role": "maker",
      "source": "MS Learn",
      "title": "Manage models in AI Builder",
      "url": "https://docs.microsoft.com/en-us/learn/modules/manage-models/?WT.mc_id=api_CatalogApi",
      "keyphrases": [
        "AI Builder",
        "models"
      ]
    }
  ],
  "@odata.nextLink": "https://corporate-training-search.search.windows.net/indexes('courses-index')/docs?api-version=2021-04-30-Preview&search=ai&$skip=50"
}

```

---

### Query 3

**Query string**: `azure`

**Index**: library

**Results**:

```json
{
  "@odata.context": "https://corporate-training-search.search.windows.net/indexes('papers-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 2.6120403,
      "content": "\nBig data stream analysis: a systematic \nliterature review\nTaiwo Kolajo1,2* , Olawande Daramola3  and Ayodele Adebiyi1,4 \n\nIntroduction\nAdvances in information technology have facilitated large volume, high-velocity of data, \nand the ability to store data continuously leading to several computational challenges. \nDue to the nature of big data in terms of volume, velocity, variety, variability, veracity, \nvolatility, and value [1] that are being generated recently, big data computing is a new \ntrend for future computing.\n\nBig data computing can be generally categorized into two types based on the process-\ning requirements, which are big data batch computing and big data stream computing \n\nAbstract \n\nRecently, big data streams have become ubiquitous due to the fact that a number of \napplications generate a huge amount of data at a great velocity. This made it difficult \nfor existing data mining tools, technologies, methods, and techniques to be applied \ndirectly on big data streams due to the inherent dynamic characteristics of big data. In \nthis paper, a systematic review of big data streams analysis which employed a rigorous \nand methodical approach to look at the trends of big data stream tools and technolo-\ngies as well as methods and techniques employed in analysing big data streams. It \nprovides a global view of big data stream tools and technologies and its comparisons. \nThree major databases, Scopus, ScienceDirect and EBSCO, which indexes journals and \nconferences that are promoted by entities such as IEEE, ACM, SpringerLink, and Elsevier \nwere explored as data sources. Out of the initial 2295 papers that resulted from the \nfirst search string, 47 papers were found to be relevant to our research questions after \nimplementing the inclusion and exclusion criteria. The study found that scalability, \nprivacy and load balancing issues as well as empirical analysis of big data streams and \ntechnologies are still open for further research efforts. We also found that although, sig-\nnificant research efforts have been directed to real-time analysis of big data stream not \nmuch attention has been given to the preprocessing stage of big data streams. Only a \nfew big data streaming tools and technologies can do all of the batch, streaming, and \niterative jobs; there seems to be no big data tool and technology that offers all the key \nfeatures required for now and standard benchmark dataset for big data streaming ana-\nlytics has not been widely adopted. In conclusion, it was recommended that research \nefforts should be geared towards developing scalable frameworks and algorithms that \nwill accommodate data stream computing mode, effective resource allocation strategy \nand parallelization issues to cope with the ever-growing size and complexity of data.\n\nKeywords: Big data stream analysis, Stream computing, Big data streaming tools and \ntechnologies\n\nOpen Access\n\n© The Author(s) 2019. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creat iveco mmons .org/licen ses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nSURVEY PAPER\n\nKolajo et al. J Big Data            (2019) 6:47  \nhttps://doi.org/10.1186/s40537-019-0210-7\n\n*Correspondence:   \ntaiwo.kolajo@stu.cu.edu.ng; \ntaiwo.kolajo@fulokoja.edu.ng \n1 Department of Computer \nand Information Sciences, \nCovenant University, Ota, \nNigeria\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0001-6780-2495\nhttp://orcid.org/0000-0001-6340-078X\nhttp://orcid.org/0000-0002-3114-6315\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40537-019-0210-7&domain=pdf\n\n\nPage 2 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\n[2]. Big data batch processing is not sufficient when it comes to analysing real-time \napplication scenarios. Most of the data generated in a real-time data stream need real-\ntime data analysis. In addition, the output must be generated with low-latency and any \nincoming data must be reflected in the newly generated output within seconds. This \nnecessitates big data stream analysis [3].\n\nThe demand for stream processing is increasing. The reason being not only that huge \nvolume of data need to be processed but that data must be speedily processed so that \norganisations or businesses can react to changing conditions in real-time.\n\nThis paper presents a systematic review of big data stream analysis. The purpose is to \npresent an overview of research works, findings, as well as implications for research and \npractice. This is necessary to (1) provide an update about the state of research, (2) iden-\ntify areas that are well researched, (3) showcase areas that are lacking and need further \nresearch, and (4) build a common understanding of the challenges that exist for the ben-\nefit of the scientific community.\n\nThe rest of the paper is organized as follows: “Background and related work” section \nprovides information on stream computing and big data stream analysis and the key \nissues involved in it and presents a review on big data streaming analytics. In “Research \nmethod” section, the adopted research methodology is discussed, while “Result” section \npresents the findings of the study. “Discussion” section presents a detailed evaluation \nperformed on big data stream analysis, “Limitation of the review” section highlights the \nlimitations of the study, while “Conclusion and further work” concludes the paper.\n\nBackground and related work\nStream computing\n\nStream computing refers to the processing of massive amount of data generated at high-\nvelocity from multiple sources with low latency in real-time. It is a new paradigm neces-\nsitated because of new sources of data generating scenarios which include ubiquity of \nlocation services, mobile devices, and sensor pervasiveness [4]. It can be applied to the \nhigh-velocity flow of data from real-time sources such as the Internet of Things, Sensors, \nmarket data, mobile, and clickstream.\n\nThe fundamental assumption of this paradigm is that the potential value of data lies in \nits freshness. As a result, data are analysed as soon as they arrive in a stream to produce \nresult as opposed to what obtains in batch computing where data are first stored before \nthey are analysed. There is a crucial need for parallel architectures and scalable com-\nputing platforms [5]. With stream computing, organisations can analyse and respond in \nreal-time to rapidly changing data. Streaming processing frameworks include Storm, S4, \nKafka, and Spark [6–8]. The real contrasts between the batch processing and the stream \nprocessing paradigms are outlined in Table 1.\n\nIncorporating streaming data into decision-making process necessitates a program-\nming paradigm called stream computing. With stream computing, fairly static questions \ncan be evaluated on data in motion (i.e. real-time data) continuously [9].\n\nBig data stream analysis\n\nThe essence of big data streaming analytics is the need to analyse and respond to real-\ntime streaming data using continuous queries so that it is possible to continuously \n\n\n\nPage 3 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nperform analysis on the fly within the stream. Stream processing solutions must be \nable to handle a real-time, high volume of data from diverse sources putting into con-\nsideration availability, scalability and fault tolerance. Big data stream analysis involves \nassimilation of data as an infinite tuple, analysis and production of actionable results \nusually in a form of stream [10].\n\nIn a stream processor, applications are represented as data flow graph made up of \noperations and interconnected streams as depicted in Fig. 1. In a streaming analytics \nsystem, application comes in a form of continuous queries, data are ingested continu-\nously, analysed and correlated, and stream of results are generated. Streaming analytic \napplications is usually a set of operators connected by streams. Streaming analytics \nsystems must be able to identify new information, incrementally build models and \naccess whether the new incoming data deviate from model predictions [9].\n\nThe idea of streaming analytics is that each of the received data tuples is processed \nin the data processing node. Such processing includes removing duplicates, filling \nmissing data, data normalization, parsing, feature extraction, which are typically done \nin a single pass due to the high data rates of external feeds. When a new tuple arrives, \nthis node is triggered, and it expels tuples older than the time specified in the sliding \nwindow (sliding window is a typical example of windows used in stream computing \nwhich keeps only the latest tuples up to the time specified in the windows). A window \n\nTable 1 Comparison between batch processing and streaming processing [82]\n\nDimension Batch processing Streaming processing\n\nInput Data chunks Stream of new data or updates\n\nData size Known and finite Infinite or unknown in advance\n\nHardware Multiple CPUs Typical single limited amount of memory\n\nStorage Store Not store or store non-trivial portion in memory\n\nProcessing Processed in multiple rounds A single or few passes over data\n\nTime Much longer A few seconds or even milliseconds\n\nApplications Widely adopted in almost every domain Web mining, traffic monitoring, sensor networks\n\nFig. 1 Data flow graph of a stream processor. The figure shows how applications (made up of operations and \ninterconnected streams) are represented as data flow graph in a stream processor [10]\n\n\n\nPage 4 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nis referred to as a logical container for data tuples received. It defines how frequently \ndata is refreshed in the container as well as when data processing is triggered [4].\n\nKey issues in big data stream analysis\n\nBig data stream analysis is relevant when there is a need to obtain useful knowledge \nfrom current happenings in an efficient and speedy manner in order to enable organisa-\ntions to quickly react to problems, or detect new trends which can help improve their \nperformance. However, there are some challenges such as scalability, integration, fault-\ntolerance, timeliness, consistency, heterogeneity and incompleteness, load balancing, \nprivacy issues, and accuracy [3, 11–18] which arises from the nature of big data streams \nthat must be dealt with.\n\nScalability\n\nOne of the main challenges in big data streaming analysis is the issue of scalability. The \nbig data stream is experiencing exponential growth in a way much faster than computer \nresources. The processors follow Moore’s law, but the size of data is exploding. There-\nfore, research efforts should be geared towards developing scalable frameworks and \nalgorithms that will accommodate data stream computing mode, effective resource allo-\ncation strategy and parallelization issues to cope with the ever-growing size and com-\nplexity of data.\n\nIntegration\n\nBuilding a distributed system where each node has a view of the data flow, that is, every \nnode performing analysis with a small number of sources, then aggregating these views \nto build a global view is non-trivial. An integration technique should be designed to ena-\nble efficient operations across different datasets.\n\nFault‑tolerance\n\nHigh fault-tolerance is required in life-critical systems. As data is real-time and infinite \nin big data stream computing environments, a good scalable high fault-tolerance strat-\negy is required that allows an application to continue working despite component failure \nwithout interruption.\n\nTimeliness\n\nTime is of the essence for time-sensitive processes such as mitigating security threats, \nthwarting fraud, or responding to a natural disaster. There is a need for scalable architec-\ntures or platforms that will enable continuous processing of data streams which can be \nused to maximize the timeliness of data. The main challenge is implementing a distrib-\nuted architecture that will aggregate local views of data into global view with minimal \nlatency between communicating nodes.\n\nConsistency\n\nAchieving high consistency (i.e. stability) in big data stream computing environments is \nnon-trivial as it is difficult to determine which data are needed and which nodes should \nbe consistent. Hence a good system structure is required.\n\n\n\nPage 5 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nHeterogeneity and incompleteness\n\nBig data streams are heterogeneous in structure, organisations, semantics, accessi-\nbility and granularity. The challenge here is how to handle an always ever-increas-\ning data, extract meaningful content out of it, aggregate and correlate streaming \ndata from multiple sources in real-time. A competent data presentation should be \ndesigned to reflect the structure, diversity and hierarchy of the streaming data.\n\nLoad balancing\n\nA big data stream computing system is expected to be self-adaptive to data streams \nchanges and avoid load shedding. This is challenging as dedicating resources to cover \npeak loads 24/7 is impossible and load shedding is not feasible when the variance \nbetween the average load and the peak load is high. As a result, a distributing envi-\nronment that automatically streams partial data streams to a global centre when local \nresources become insufficient is required.\n\nHigh throughput\n\nDecision with respect to identifying the sub-graph that needs replication, how many \nreplicas are needed and the portion of the data stream to assign to each replica is an \nissue in big data stream computing environment. There is a need for good multiple \ninstances replication if high throughput is to be achieved.\n\nPrivacy\n\nBig data stream analytics created opportunities for analyzing a huge amount of data \nin real-time but also created a big threat to individual privacy. According to the Inter-\nnational Data Cooperation (IDC), not more than half of the entire information that \nneeds protection is effectively protected. The main challenge is proposing techniques \nfor protecting a big data stream dataset before its analysis.\n\nAccuracy\n\nOne of the main objectives of big data stream analysis is to develop effective tech-\nniques that can accurately predict future observations. However, as a result of inher-\nent characteristics of big data such as volume, velocity, variety, variability, veracity, \nvolatility, and value, big data analysis strongly constrain processing algorithms spatio-\ntemporally and hence stream-specific requirements must be taken into consideration \nto ensure high accuracy.\n\nRelated work\n\nThis section discusses some of the previous research efforts that relate to big data \nstreaming analytics.\n\nThe work of [13] presented a review of various tools, technologies and methods \nfor big data analytics by categorizing big data analytics literature according to their \nresearch focus. This paper is different in that it presents a systematic literature review \nthat focused on big data “streaming” analytics.\n\n\n\nPage 6 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nAuthors in [19] presented a systematic review of big data analytics in e-commerce. The \nstudy explored characteristics, definitions, business values, types and challenges of big \ndata analytics in the e-commerce landscape. Likewise, [20] conducted a study that is cen-\ntred on big data analytics in technology and organisational resource management specifi-\ncally focusing on reviews that present big data challenges and big data analytics methods. \nAlthough they are systematic reviews, the focus is not, particularly on big data streaming.\n\nAuthors in [21] presented the status of empirical research and application areas in big \ndata by employing a systematic mapping method. In the same vein, authors in [22] also \nconducted a survey on big data technologies and machine learning algorithms with a \nparticular focus on anomaly detection. A systematic review of literature which aims to \ndetermine the scope, application, and challenges of big data analytics in healthcare was \npresented by [23]. The work of [2] presented a review of four big data streaming tools \nand technologies. While the study conducted in this paper provided a comprehensive \nreview of not only big data streaming tools and technologies but also methods and tech-\nniques employed in analyzing big data streams. In addition, authors [2] did not provide a \nclear explanation of the methodical approach for selecting the reviewed papers.\n\nResearch method\nThe study was grounded in a systematic literature review of tools and technologies \nwith methods and techniques used in analysing big data streams by adopting [24, 25] as \nmodels.\n\nResearch question\n\nThe study tries to answer the following research questions:\n\nResearch Question 1: What are the tools and technologies employed for big data \nstream analysis?\nResearch Question 2: What methods and techniques are used in analysing big data \nstreams?\nResearch Question 3: What do these tools and technologies have in common and \ntheir differences in terms of concept, purpose and capabilities?\nResearch Question 4: What are the limitations and strengths of these tools and tech-\nnologies?\nResearch Question 5: What are the evaluation techniques or benchmarks used for \nevaluating big data streaming tools and technology?\n\nSearch string\n\nCreating a good search string requires structuring in terms of population, compari-\nson, intervention and outcome [24]. Relevant publications were identified by forming \na search string that combined keywords driven by the research questions earlier stated. \nThe searches were conducted by employing three standard database indexes, which are \nScopus, Science Direct and EBSCOhost. The search string is “big data stream analysis” \nOR “big data stream technologies” OR “big data stream framework” OR “big data stream \nalgorithms” OR “big data stream analysis tools” OR “big data stream processing” OR “big \n\n\n\nPage 7 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndata stream analysis reviews” OR “big data stream literature review” OR “big data stream \nanalytics”.\n\nData sources\n\nAs research becomes increasingly interdisciplinary, global and collaborative, it is expedi-\nent to select from rich and standard databases. The databases consulted are as follows:\n\n i. Scopus1: Scopus is a bibliographic database containing abstracts and citations for \nacademic journal articles launched in 2004. It covers nearly 36,377 titles from over \n11,678 publishers of which 34,346 are peer-reviewed journals, delivering a compre-\nhensive overview of the world’s research output in the scientific, technical, medi-\ncal, and social sciences (including arts and humanities). It is the largest abstract \nand citation database of peer-reviewed literature.\n\n ii. ScienceDirect2: ScienceDirect is Elsevier’s leading information solution for \nresearchers, students, teachers, information professionals and healthcare profes-\nsionals. It provides both subscription-based and open access-based to a large data-\nbase combining authoritative, full-text scientific, technical and health publications \nwith smart intuitive functionality. It covers over 14 million publications from over \n3800 journals and more than 35,000 books. The journals are grouped into four \ncategories: Life Sciences, Physical Sciences and Engineering, Health Sciences, and \nSocial Sciences and Humanities.\n\n iii. EBSCOhost3: EBSCOhost covers a wide range of bibliographic and full-text data-\nbases for researchers, providing electronic journal service available to both cor-\nporate and academic researchers. It has a total of 16,711 journals and magazine \nindexed and abstracted of which 14,914 are peer-reviewed; more than 900,000 \nhigh-quality e-books and titles and over 60,000 audiobooks from more than 1500 \nmajor academic publishers.\n\n iv. ResearchGate4: A free online professional network for scientists and researchers to \nask and answer questions, share papers and find collaborators. It covers over 100 \nmillion publications from over 11 million researchers. ResearchGate was used as \na secondary source where the authors could not access some papers due to lack of \nsubscription.\n\nData retrieval\n\nThe search was conducted in Scopus, ScienceDirect and EBSCOhost since most of \nthe high impact journals and conferences are indexed in these set of rich databases. \nBoolean ‘OR’ was used in combining the nine (9) search strings. A total of 2295 arti-\ncles from the three databases were retrieved as shown in Table 2.\n\n1 http://www.scopu s.com.\n2 http://www.scien cedir ect.com.\n3 https ://www.ebsco host.com.\n4 https ://www.resea archg ate.net.\n\nhttp://www.scopus.com\nhttp://www.sciencedirect.com\nhttps://www.ebscohost.com\nhttps://www.reseaarchgate.net\n\n\nPage 8 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nFurther refinement was performed by (i) limiting the search to journals and confer-\nence papers; (ii) selecting computer science and IT related as the subject domain; (iii) \nselecting ACM, IEEE, SpringerLink, Elsevier as sources; and year of publication to \nbetween 2004 and 2018. The year range was selected due to the fact that interest in \nbig data stream analysis actually started in 2004. At this stage, a total of 1989 papers \nwere excluded leaving a total of 315 papers (see Table  3). The result of the search \nstring was exported to PDF.\n\nBy going through the title of the papers, 111 seemingly relevant papers were extracted \nexcluding a total number of 213 that were not relevant at this stage (see Table 4).\n\nThe abstracts of 111 papers and introduction (for papers that the abstracts were not \nclear enough) were then read to have a quick overview of the paper and to ascertain \nwhether they are suitable or at variance with the research questions. The citations of \nthe papers were exported to Microsoft Excel for easy analysis. The papers were grouped \ninto three categories; “relevant”, “may be relevant” and “irrelevant”. The “relevant” papers \nwere marked with black colour, “may be relevant” and “irrelevant” with green and red \ncolours respectively. At the end of this stage, 45 papers were classified as “relevant”, 9 \npapers as “may be relevant” and 11 as “irrelevant”. Looking critically at the abstract again, \n18 papers were excluded by using the exclusion criteria leaving a total of 47 papers (see \nTable 5) which were manually reviewed in line with the research questions.\n\nInclusion criteria\n\nPapers published in journals, peer-reviewed conferences, workshops, technical and \nsymposium from 2004 and 2018 were included. In addition, the most recent papers \nwere selected in case of papers with similar investigations and results.\n\nTable 2 First search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 2097 65 133 2295\n\nTable 3 Second search string result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 196 27 92 315\n\nTable 4 Third Search string refinement result\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 64 23 24 111\n\nTable 5 Final Selection\n\nScopus ScienceDirect EBSCOhost Total\n\nNumber of papers 25 10 12 47\n\n\n\nPage 9 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nExclusion criteria\n\nPapers that belong to the following categories were excluded from selection as part of \nthe primary study: (i) papers written in source language other than English; (ii) papers \nwith an abstract and or introduction that does not clearly define the contributions of the \nwork; (iii) papers whose abstract do not relate to big data stream analysis.\n\nResult\nThe findings of the study are now presented with respect to the research questions that \nguided the execution of the systematic literature review.\n\nResearch Question 1: What are the tools and technologies employed for big data stream \n\nanalysis?\n\nBig data stream platforms provide functionalities and features that enable big data \nstream applications to develop, operate, deploy, and manage big data streams. Such \nplatforms must be able to pull in streams of data, process the data and stream it back \nas a single flow. Several tools and technologies have been employed to analyse big data \nstreams. In response to the growing demand for big data streaming analytics, a large \nnumber of alternative big data streaming solutions have been developed both by the \nopen source community and enterprise technology vendors. According to [26], there are \nsome factors to consider when selecting big data streaming tools and technologies in \norder to make effective data management decisions. These are briefly described below.\n\nShape of the data\n\nStreaming data sources require serialization technologies for capturing, storing and rep-\nresenting such high-velocity data. For instance, some tools and technologies allow pro-\njection of different structures across data stores, giving room for flexibility for storage \nand access of data in different ways. However, the performance of such platforms may \nnot be suitable for high-velocity data.\n\nData access\n\nThere is a need to put into consideration how the data will be accessed by users and \napplications. For instance, many NoSQL databases require specific application interfaces \nfor data access. Hence there is a need to consider the integration of some other neces-\nsary tools for data access.\n\nAvailability and consistency requirement\n\nIf a distributed system is needed, then CAP theorem states that consistency and avail-\nability cannot be both guaranteed in the presence of network partition (i.e. when there is \na break in the network). In such a scenario, consistency is often traded off for availability \nto ensure that requests can always be processed.\n\nWorkload profile required\n\nPlatform as a service deployment may be appropriate for a spike load profile platform. \nIf platform distribution can be deployed on Infrastructure as a service cloud, then this \noption may be preferred as users will need to pay only when processing. On-premise \n\n\n\nPage 10 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\ndeployment may be considered for predictable or consistent loads. But if workloads are \nmixed (i.e. consistent flows or spikes), a combination of cloud and on-premise approach \nmay be considered so as to give room for easy integration of web-based services or soft-\nware and access to critical functions on the go.\n\nLatency requirement\n\nIf a minimal delay or low latency is required, key-value stores may be considered or bet-\nter still, an in-memory solution which allows the process of large datasets in real-time is \nrequired in order to optimize the data loading procedure.\n\nThe tools and technologies for big data stream analysis can be broadly categorized into \ntwo, which are open source and proprietary solutions. These are listed in Tables 6 and 7.\n\nThe selection of big data streaming tools and technologies should be based on the impor-\ntance of each factor earlier mentioned in this section. Proprietary solutions may not be eas-\nily available because of pricing and licensing issues. While open source supports innovation \nand development at a large scale, careful selection must be made especially when choosing \na recent technology still in production due to limited maturity and lack of support from \nacademic researchers or developer communities. In addition, open source solutions may \nlead to outdating and modification challenges [27]. Moreover, the selection of whether pro-\nprietary or open source or combination of both should depend on the problem to address, \nthe understanding of the true costs, and benefits of both open and proprietary solutions.\n\nTable 6 Open source tools and technologies for big data stream analysis\n\nTools and technology Article\n\nBlockMon [83]\n\nNoSQL [4, 84–86]\n\nSpark streaming [67, 87–91]\n\nApache storm [68, 85, 86, 92–97]\n\nKafka [85, 91, 95, 96, 98]\n\nYahoo! S4 [6, 45, 87, 99]\n\nApache Samza [46, 67, 100]\n\nPhoton [67, 101]\n\nApache Aurora [67, 102]\n\nMavEStream [103]\n\nEsperTech [104, 105]\n\nRedis [106]\n\nC-SPARQL [107, 108]\n\nSAMOA [56, 78, 109]\n\nCQELS [108, 110, 111]\n\nETALIS [112]\n\nXSEQ [73]\n\nApache Kylin [113]\n\nSplunk stream [114]\n\n\n\nPage 11 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nResearch Question 2: What methods and techniques are used in analysing big data \n\nstreams?\n\nGiven the real-time nature, velocity and volume of social media streams, the clus-\ntering algorithms that are applied on streaming data must be highly scalable and \nefficient. Also, the dynamic nature of data makes it difficult to know the required or \ndesirable number of clusters in advance. This renders partitioning clustering tech-\nniques (such as k-median, k-means and k-medoid) or expectation-maximization \n(EM) algorithms-based approaches unsuitable for analysing real-time social media \ndata because they require prior knowledge of clusters in advance. In addition, due \nto concept drift inherent in social media streams, scalable graph partitioning algo-\nrithms are not also suitable because of their tendency towards balanced partitioning. \nSocial media streams must be analysed dynamically in order to provide decisions at \nany given time within a limited space and time window [28–30].\n\nDensity-based clustering algorithm (such as DenStream, OpticStream, Flock-\nStream, Exclusive and Complete Clustering) unlike partitioning algorithms does not \nrequire apriori number of clusters in advance and can detect outliers [31]. However, \nthe issue with density-based clustering algorithms is that most of them except for few \nlike HDDStream, PreDeCon-Stream and PKS-Stream (which are memory intensive) \nperform less efficiently in the face of high dimensional data and as a result are not \nsuitable for analyzing social media streams [32].\n\nThreshold-based techniques, hierarchical clustering, and incremental clustering \nor online clustering are more relevant to social media analysis. Several online thresh-\nold-based stream clustering approaches or incremental clustering approaches such as \nMarkov Random Field [33, 34], Online Spherical K-means [35], and Condensed Clusters \n[36] have been adopted. Incremental approaches are suitable for continuously generated \ndata grouping by setting a maximum similarity threshold between the incoming stream \n\nTable 7 Proprietary tools and technologies for big data stream analysis\n\nTools and technology Article\n\nCodeBlue [115]\n\nAnodot [116]\n\nCloudet [117]\n\nSentiment brand monitoring [118]\n\nNumenta [119]\n\nElastic streaming processing engine [120]\n\nMicrosoft azure stream analytics [121]\n\nIBM InfoSphere streams [8, 122]\n\nGoogle MillWheel [123]\n\nArtemis [124]\n\nWSO2 analytics [125]\n\nMicrosoft StreamInsight [126]\n\nTIBCO StreamBase [127]\n\nStriim [128]\n\nKyvos insights [129]\n\nAtScale [130, 131]\n\nLambda architecture [57]\n\n\n\nPage 12 of 30Kolajo et al. J Big Data            (2019) 6:47 \n\nand the existing clusters. Much work has been done in improving the efficiency of online \nclustering algorithms, however, little research efforts have been directed to threshold \nand fragmentation issues. Incremental algorithm threshold setting should employ adap-\ntive approach instead of relying on static values [37, 38]. Some of the methods and tech-\nniques that have been employed in analysing big data streams are outlined in Table 8.\n\nTable 8 Methods and techniques for big data stream analysis\n\nMethods and techniques Article\n\nSPADE [132]\n\nLocally supervised metric learning (LSML) [133]\n\nKTS [106]\n\nMultinomial latent dirichlet allocation [106]\n\nVoltage clustering algorithm [106]\n\nLocality sensitive hashing (LSH) [134]\n\nUser profile vector update algorithm [134]\n\nTag assignment stream clustering (TASC) [134]\n\nStreamMap [117]\n\nDensity cognition [117]\n\nQRS detection algorithm [87]\n\nForward chaining rule [110]\n\nStream [135]\n\nCluStream [136, 137]\n\nHPClustering [138]\n\nDenStream [139]\n\nD-Stream [140]\n\nACluStream [141]\n\nDCStream [142]\n\nP-Stream [143]\n\nADStream [144]\n\nContinuous query processing (CQR) [145]\n\nFPSPAN-growth [146]\n\nOutlier method for cloud computing algorithm (OMCA) [147]\n\nMulti-query optimization strategy (MQOS) [148]\n\nParallel K-means clustering [72]\n\nVisibly push down automata (VPA) [73]\n\nIncremental MI outlier detection algorithm (Inc I-MLOF) [149]\n\nAdaptive windowing based online ensemble (AWOE) [74]\n\nDynamic prime-number based security verification [84]\n\nK-anonymity, I-diversity, t-closeness [90]\n\nSingular spectrum matrix completion (SS-MC) [76]\n\nTemporal fuzzy concept analysis [96]\n\nECM-sketch [77]\n\nNearest neighbour [91]\n\nMarkov chains [91]\n\nBlock-QuickSort-AdjacentJobMatch [86]\n\nBlock-QuickSort-OverlapReplicate ",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmRhdGEuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zNDA1MzctMDE5LTAyMTAtNy5wZGY1",
      "keyphrases": [
        "Big data stream analysis",
        "systematic literature review"
      ],
      "title": "Big data stream analysis: a systematic literature review",
      "author": "Taiwo Kolajo "
    }
  ]
}
```

---

### Query 4

**Query string**: `ai`

**Index**: library

**Results**:

```json
{
  "@odata.context": "https://corporate-training-search.search.windows.net/indexes('papers-index')/$metadata#docs(*)",
  "value": [
    {
      "@search.score": 2.9396675,
      "content": "\nORIGINAL RESEARCH\n\nDiscriminated by an algorithm: a systematic review\nof discrimination and fairness by algorithmic decision-\nmaking in the context of HR recruitment and HR\ndevelopment\n\nAlina Köchling1\n• Marius Claus Wehner1\n\nReceived: 15 October 2019 / Accepted: 1 November 2020 / Published online: 20 November 2020\n\n� The Author(s) 2020\n\nAbstract Algorithmic decision-making is becoming increasingly common as a new\n\nsource of advice in HR recruitment and HR development. While firms implement\n\nalgorithmic decision-making to save costs as well as increase efficiency and\n\nobjectivity, algorithmic decision-making might also lead to the unfair treatment of\n\ncertain groups of people, implicit discrimination, and perceived unfairness. Current\n\nknowledge about the threats of unfairness and (implicit) discrimination by algo-\n\nrithmic decision-making is mostly unexplored in the human resource management\n\ncontext. Our goal is to clarify the current state of research related to HR recruitment\n\nand HR development, identify research gaps, and provide crucial future research\n\ndirections. Based on a systematic review of 36 journal articles from 2014 to 2020,\n\nwe present some applications of algorithmic decision-making and evaluate the\n\npossible pitfalls in these two essential HR functions. In doing this, we inform\n\nresearchers and practitioners, offer important theoretical and practical implications,\n\nand suggest fruitful avenues for future research.\n\nKeywords Fairness � Discrimination � Perceived fairness � Ethics �\nAlgorithmic decision-making in HRM � Literature review\n\n1 Introduction\n\nAlgorithmic decision-making in human resource management (HRM) is becoming\n\nincreasingly common as a new source of information and advice, and it will gain\n\nmore importance due to the rapid growth of digitalization in organizations.\n\n& Alina Köchling\n\nalina.koechling@hhu.de\n\n1 Faculty of Business Administration and Economics, Heinrich-Heine-University Düsseldorf,\n\nUniversitätsstrasse 1, 40225 Dusseldorf, Germany\n\n123\n\nBusiness Research (2020) 13:795–848\n\nhttps://doi.org/10.1007/s40685-020-00134-w\n\nhttp://orcid.org/0000-0001-7039-9852\nhttp://orcid.org/0000-0002-1932-3155\nhttp://crossmark.crossref.org/dialog/?doi=10.1007/s40685-020-00134-w&domain=pdf\nhttps://doi.org/10.1007/s40685-020-00134-w\n\n\nAlgorithmic decision-making is defined as automated decision-making and remote\n\ncontrol, as well as standardization of routinized workplace decisions (Möhlmann\n\nand Zalmanson 2017). Algorithms, instead of humans, make decisions, and this has\n\nimportant individual and societal implications in organizational optimization\n\n(Chalfin et al. 2016; Lee 2018; Lindebaum et al. 2019). These changes in favor\n\nof algorithmic decision-making make it easier to discover hidden talented\n\nemployees in organizations and review a large number of applications automatically\n\n(Silverman and Waller 2015; Carey and Smith 2016; Savage and Bales 2017). In a\n\nsurvey of 200 artificial intelligence (AI) specialists from German companies, 79%\n\nstated that AI is irreplaceable for competitive advantages (Deloitte 2020). Several\n\ncommercial providers, such as Google, IBM, SAP, and Microsoft, already offer\n\nalgorithmic platforms and systems that facilitate current human resource (HR)\n\npractices, such as hiring and performance measurements (Walker 2012). In turn,\n\nwell-known and large companies, such as Vodafone, Intel, Unilever, and Ikea, apply\n\nalgorithmic decision-making in HR recruitment and HR development (Daugherty\n\nand Wilson 2018; Precire 2020).\n\nThe major driving forces for algorithmic decision-making are savings in both\n\ncosts and time, minimizing risks, enhancing productivity, and increasing certainty in\n\ndecision-making (Suen et al. 2019; McDonald et al. 2017; McColl and Michelotti\n\n2019; Woods et al. 2020). Besides these economic reasons, firms seek to diminish\n\nthe human biases (e.g., prejudices and personal beliefs) by applying algorithmic\n\ndecision-making, thereby increasing the objectivity, consistency, and fairness of the\n\nHR recruitment as well as HR development processes (Langer et al. 2019;\n\nFlorentine 2016; Raghavan et al. 2020). For example, Deloitte argues that the\n\nalgorithmic decision-making system always manages each application with the\n\nsame attention according to the same requirements and criteria (Deloitte 2018). At\n\nfirst glance, algorithmic decision-making seems to be more objective and fairer than\n\nhuman decision-making (Lepri et al. 2018).\n\nHowever, there is a possible threat of discrimination and unfairness by relying\n\nsolely on algorithmic decision-making (e.g., (Lee 2018; Lindebaum et al. 2019;\n\nSimbeck 2019)). In general, discrimination is defined as the unequal treatment of\n\ndifferent groups based on gender, age, or ethnicity instead of on qualitative\n\ndifferences, such as individual performance (Arrow 1973). Algorithms produce\n\ndiscrimination or biased outcomes if they are trained on inaccurate (Kim 2016),\n\nbiased (Barocas and Selbst 2016), or unrepresentative input data (Suresh and Guttag\n\n2019). Consequently, algorithms are vulnerable to produce or replicate biased\n\ndecisions if their input (or training) data are biased (Chander 2016).\n\nComplicating this issue, biases and discrimination are often only recognized after\n\nalgorithms have made a decision. As a prominent example stemming from the\n\ncurrent debate around transparency, bias, and fairness in algorithmic decision-\n\nmaking (Dwork et al. 2012; Lepri et al. 2018; Diakopoulos 2015), the hiring\n\nalgorithms applied by the American e-commerce specialist Amazon yielded an\n\nextreme disadvantage of female applicants, which finally led Amazon to shut down\n\nthe complete algorithmic decision-making for their hiring decision (Dastin 2018;\n\nMiller 2015). Thus, the lack of transparency and accountability of the input data, the\n\nalgorithm itself, and the factors influencing algorithmic outcomes are potential\n\n796 Business Research (2020) 13:795–848\n\n123\n\n\n\nissues associated with algorithmic decision-making (Citron and Pasquale 2014;\n\nPasquale 2015). Another question remains whether applicants and/or employees\n\nperceive the algorithmic decision-making to be fair. Previous studies showed that\n\napplicants’ and employees’ acceptance of algorithmic decision-making is lower in\n\nHR recruitment and HR development compared to common procedures conducted\n\nby humans (Kaibel et al. 2019; Langer et al. 2019; Lee 2018).\n\nConsequently, there is a discrepancy between the enthusiasm about algorithmic\n\ndecision-making as a panacea for inefficiencies and labor shortages on one hand and\n\nthe threat of discrimination and unfairness of algorithmic decision-making on the\n\nother side. While the literature in the field of computer science has already\n\naddressed the issues of biases, knowledge about the potential downsides of\n\nalgorithmic decision-making is still in its infancy in the field of HRM despite its\n\nimportance due to increased digitization and automation in HRM. This heteroge-\n\nneous state of research on discrimination and fairness raises distinct challenges for\n\nfuture research. From a practical point of view, it is problematic if large and well-\n\nknown companies implement algorithms without being aware of the possible pitfalls\n\nand negative consequences. Thus, to move the field forward, it is paramount to\n\nsystematically review and synthesize existing knowledge about biases and\n\ndiscrimination in algorithmic decision-making and to offer new research avenues.\n\nThe aim of this study is threefold. First, this review creates an awareness of\n\npotential biases and discrimination resulting from algorithmic decision-making in\n\nthe context of HR recruitment and HR development. Second, this study contributes\n\nto the current literature by informing both researchers and practitioners about the\n\npotential dangers of algorithmic decision-making in the HRM context. Finally, we\n\nguide future research directions with an understanding of existing knowledge and\n\ngaps in the literature. To this end, the present paper conducts a systematic review of\n\nthe current literature with a focus on HR recruitment and HR development. These\n\ntwo HR functions deal with the potential of future and current employees and the\n\n(automatic) prediction of person-organization fit, career development, and future\n\nperformance (Huselid 1995; Walker 2012). Decisions made by algorithms and AI in\n\nthese two important HR areas have serious consequences for individuals, the\n\ncompany, and society concerning ethics and both procedural and distributive\n\nfairness (Ötting and Maier 2018; Lee 2018; Tambe et al. 2019; Cappelli et al. 2020).\n\nOur study contributes to the existing body of research in several ways. First, the\n\nsystematic literature review contributes to the literature by highlighting the current\n\ndebate on ethical issues associated with algorithmic decision-making, including bias\n\nand discrimination (Barocas and Selbst 2016). Second, our research provides\n\nillustrative examples of various algorithmic decision-making tools used in HR\n\nrecruitment, HR development, and their potential for discrimination and perceived\n\nfairness. Moreover, our systematic review underlines the fact that it is a timely topic\n\ngaining enormous importance. Companies will face legal and reputational risk if\n\ntheir HR recruitment and HR development methods turn out to be discriminatory,\n\nand applicants and employees may consider the algorithmic selection or develop-\n\nment process to be unfair.\n\nFor this reason, companies need to know that the use of algorithmic decision-\n\nmaking can yield to discrimination, unfairness, and dissatisfaction in the context of\n\nBusiness Research (2020) 13:795–848 797\n\n123\n\n\n\nHRM. We offer an understanding of how discrimination might arise when\n\nimplementing algorithmic decision-making. We try to give guidance on how\n\ndiscrimination and perceived unfairness could be avoided and provide detailed\n\ndirections for future research in the existing literature, especially in the HRM field.\n\nMoreover, we identify several research gaps, mainly a lacking focus on perceived\n\nfairness.\n\nThe paper is organized as follows: first, we give an understanding of key terms\n\nand definitions. Afterward, we present the methodology of our systematic literature\n\nreview accompanied by a descriptive analysis of the reviewed literature. This is\n\nfollowed by an illustration of the current state of knowledge on algorithmic\n\ndecision-making and subsequent discussion. Finally, we offer practical as well as\n\ntheoretical implications and outline future research avenues.\n\n2 Conceptual background and definitions\n\n2.1 Definition of algorithms\n\nThe Oxford Living Dictionary defines algorithms as ‘‘processes or sets of rules to be\n\nfollowed in calculations or other problem-solving operations, especially by a\n\ncomputer.’’ Möhlmann and Zalmanson (2017) refer to algorithmic decision-making\n\nas automated decision-making and remote control, and standardization of routinized\n\nworkplace decision. Thus, in this paper, we use the term algorithmic decision-\n\nmaking to describe a computational mechanism that autonomously makes decisions\n\nbased on rules and statistical models without explicit human interference (Lee\n\n2018). Algorithms are the basis for several AI decision tools.\n\nAI is an umbrella term for a wide array of models, methods, and prescriptions\n\nused to simulate human intelligence, often when it comes to collecting, processing,\n\nand acting on data. AI applications can apply rules, learn over time through the\n\nacquisition of new data and information, and adapt to changes in the environment\n\n(Russell and Norvig 2016). AI includes several different research areas, such as\n\nmachine learning (ML), speech and image recognition, and natural language\n\nprocessing (NLP) (Kaplan and Haenlein 2019; Paschen et al. 2020).\n\nAs mentioned, the basis for many AI decision-making tools used in HR are ML\n\nalgorithms, which can be categorized into three major types: supervised, unsuper-\n\nvised, and reinforcement learning (Lee and Shin 2020). Supervised ML algorithms\n\naim to make predictions (often divided into classification- or regression-type\n\nproblems), given the input data and desired outputs considered as the ground truth.\n\nHuman experts often provide these labels and thus provide the algorithm with the\n\nground truth. To replicate human decisions or to make predictions, the algorithm\n\nlearns patterns from the labeled data and develops rules, which can be applied for\n\nfuture instances for the same problem (Canhoto and Clear 2020). In contrast, in\n\nunsupervised ML, only input data are given, and the model learns patterns from the\n\ndata without a priori labeling (Murphy 2012). Unsupervised ML algorithms capture\n\nthe structural behaviors of variables in the input data for theme analysis or grouping\n\n798 Business Research (2020) 13:795–848\n\n123\n\n\n\ndata (Canhoto and Clear 2020). Finally, reinforcement learning, as a separate group\n\nof methods, is not based on fixed input/output data. Instead, the ML algorithm learns\n\nbehavior through trial-and-error interactions with a dynamic environment (Kael-\n\nbling et al. 1996).\n\nFurthermore, instead of grouping ML models as supervised, unsupervised, or\n\nreinforcement type learning, the methodologies of algorithms may also be used to\n\ncategorize ML models. Examples are probabilistic models, which may be used in\n\nsupervised or unsupervised settings (Murphy 2012), or deep learning models (Lee\n\nand Shin 2020), which rely on artificial neural networks and perform complex\n\nlearning tasks. In supervised settings, neural network models often determine the\n\nrelationship between input and output using network structures containing the so-\n\ncalled hidden layers, meaning phases of transformation of the input data. Single\n\nnodes of these layers (neurons) were first modeled after neurons in the human brain,\n\nand they resemble human thinking (Bengio et al. 2017). In other settings, deep\n\nlearning may be used, for instance, to (1) process information through multiple\n\nstages of nonlinear transformation; or (2) determine features, representations of the\n\ndata providing an advantage for, e.g., prediction tasks (Deng and Yu 2014).\n\n2.2 Reason for biases\n\nFor any estimation bY of a random variable Y , bias refers to the difference between\n\nthe expected values of bY and Y and is also referred to as systematic error\n\n(Kauermann and Kuechenhoff 2010; Goodfellow et al. 2016). Cognitive biases,\n\nspecifically, are systematic errors in human judgment when dealing with uncertainty\n\n(Kahneman et al. 1982). These cognitive biases are thought to be transferred to\n\nalgorithmic evaluations or predictions, where bias may refer to ‘‘computer systems\n\nthat systematically and unfairly discriminate against certain individuals or groups in\n\nfavor of others’’ (Friedman and Nissenbaum 1996, p. 332).\n\nAlgorithms are often characterized as ‘‘black box’’. In the context of HRM,\n\nCheng and Hackett (2019) characterize algorithms as ‘‘glass boxes’’, since some,\n\nbut not all, components of the theory are reflective. In this context, the consideration\n\nand distinction of the three core elements are necessary, namely, transparency,\n\ninterpretability, and explainability (Roscher et al. 2020). Transparency is concerned\n\nwith the ML approach, while interpretability is concerned with the ML model in\n\ncombination with the data, which means the making sense of the obtained ML\n\nmodel (Roscher et al. 2020). Finally, explainability comprises the model, the data,\n\nand human involvement (Roscher et al. 2020). Concerning the former, transparency\n\ncan be distinguished at three different levels: ‘‘[…] at the level of the entire model\n\n(simulatability), at the level of individual components, such as parameters\n\n(decomposability), and at the level of the training (algorithmic transparency)’’\n\n(Roscher et al. 2020, p. 4). Interpretability concerns the characteristics of an ML\n\nmodel that need to be understood by a human (Roscher et al. 2020). Finally, the\n\nelement of explainability is paramount in HRM. Contextual information of human\n\nand their knowledge from the domain of HRM are necessary to explain the different\n\nsets of interpretations and derive conclusions about the results of the algorithms\n\nBusiness Research (2020) 13:795–848 799\n\n123\n\n\n\n(Roscher et al. 2020). Especially in HRM, in which ML algorithms are increasingly\n\nused for prediction of variables of interest to the HR department (e.g., personality\n\ncharacteristics, employee satisfaction, and turnover intentions), it is essential to\n\nunderstand how the ML algorithm operates (e.g., how the ML algorithm uses data\n\nand weighs specific criteria) and the underlying reasons for the produced decision.\n\nIn the following, we will outline the main reasons for biases in algorithmic\n\ndecision-making and briefly summarize different biases, namely historical, repre-\n\nsentation, technical, and emergent bias. One of the main reasons for bias in\n\nalgorithmic decision-making is the quality of input data, because algorithms learn\n\nfrom historical data as an example; thus, the learning process depends on the\n\nexposed examples (Friedman and Nissenbaum 1996; Barocas and Selbst 2016;\n\nDanks and London 2017). The input data are usually historical. Consequently, if the\n\ninput data set is biased in one way or another, the subsequent analysis is biased, as\n\nwell (keyword: ‘‘garbage in, garbage out’’). For example, if the input data of an\n\nalgorithm include implicit or explicit human judgments, stereotypes, or biases, an\n\naccurate algorithmic output will inevitably entail these human judgments, stereo-\n\ntypes, and prejudices (Diakopoulos 2015; Suresh and Guttag 2019; Barfield and\n\nPagallo 2018). This bias usually exists before the creation of the system and may not\n\nbe apparent at first glance. In turn, the algorithm replicates these preexisting biases,\n\nbecause it treats all information, in which a certain kind of discrimination or bias is\n\nembedded, as a valid example (Barocas and Selbst 2016; Lindebaum et al. 2019). In\n\nthe worst case, the algorithm can yield racist or discriminatory outputs (Veale and\n\nBinns 2017). Algorithms exhibit these tendencies, even if it is not the intention of\n\nthe manual programming since they compound the historical biases of the past.\n\nThus, any predictive algorithmic decision-making tool built on historical data may\n\ninherit historical biases (Datta et al. 2015).\n\nAs an example from the recruitment process, if an algorithm is trained on\n\nhistorical employment data, integrating an implicit bias that favors white men over\n\nHispanics, then, without even being fed data on gender or ethnicity, an algorithm\n\nmay recognize patterns in the data, which expose an applicant as a member of a\n\ncertain protected group, which, historically, is less likely to be chosen for a job\n\ninterview. This, in turn, may lead to a systematic disadvantage of certain groups,\n\neven if the designer has no intention of marginalizing people based on these\n\ncategories and if the algorithm is not directly given this information (Barocas and\n\nSelbst 2016).\n\nAnother reason for biases in algorithms related to the input data is that certain\n\ngroups or characteristics are mostly underrepresented or sometimes overrepre-\n\nsented, which is also called representation bias (Barocas and Selbst 2016; Suresh\n\nand Guttag 2019; Barfield and Pagallo 2018). Any decision based on this kind of\n\nbiased data might lead to disadvantages of groups of individuals who are\n\nunderrepresented or overrepresented (Barocas and Selbst 2016). Another reason\n\nfor representation bias can be the absence of specific information (Barfield and\n\nPagallo 2018). Thus, not only the selection of measurements but also the\n\npreprocessing of the measurement data might yield to bias. ML models often\n\nevolve in several steps of feature engineering or model testing, since there is no\n\nuniversally best model (as shown in the ‘‘no free lunch’’ theorems, [see Wolpert and\n\n800 Business Research (2020) 13:795–848\n\n123\n\n\n\nMacready (1997)]. Here, the choice of the benchmark or rather the value indicating\n\nthe performance of the model is optimized through rotations of different\n\nrepresentations of the data and methods for prediction. For example, representative\n\nbias might occur if females in comparison to males are underrepresented in the\n\ntraining data of an algorithm. Hence, the outcome could be in favor of the\n\noverrepresented group (i.e., males) and, hence, lead to discriminatory outcomes.\n\nTechnical bias may arise from technical constraints or technical consideration for\n\nseveral reasons. For example, technical bias can originate from limited ‘‘[…]\n\ncomputer technology, including hardware, software, and peripherals’’ (Friedman\n\nand Nissenbaum 1996, p. 334). Another reason could be a decontextualized\n\nalgorithm that does not manage to treat all groups fairly under all important\n\nconditions (Friedman and Nissenbaum 1996; Bozdag 2013). The formalization of\n\nhuman constructs to computers can be another problem leading to technical bias.\n\nHuman constructs, such as judgments or intuitions, are often hard to quantify, which\n\nmakes it difficult or even impossible to translate them to the computer (Friedman\n\nand Nissenbaum 1996). As an example, the human interpretation of law can be\n\nambiguous and highly dependent on the specific context, making it difficult for an\n\nalgorithmic system to correctly advise in litigation (c.f., Friedman and Nissenbaum\n\n1996).\n\nIn the context of real users, emergent bias may arise. Typically, this bias occurs\n\nafter the construction as a result of changed societal knowledge, population, or\n\ncultural values (Friedman and Nissenbaum 1996). Consequently, a shift in the\n\ncontext of use might yield to problems and an emergent bias due to two reasons,\n\nnamely ‘‘new societal knowledge’’ and ‘‘mismatch between users and system\n\ndesign’’ (see Table 1 in Friedman and Nissenbaum 1996, p. 335). If it is not possible\n\nto incorporate new knowledge in society into the system design, emergent bias due\n\nto new societal knowledge occurs. The mismatch between users and system design\n\ncan occur due to changes in state-of-the-art-research or due to different values. Also,\n\nemergent bias can occur if a population uses the system with different values than\n\nthose assumed in the design process (Friedman and Nissenbaum 1996). Problems\n\noccur, for example, when users originate from a cultural context that avoids\n\ncompetition and promotes cooperative efforts, while the algorithm is trained to\n\nreward individualistic and competitive behavior (Friedman and Nissenbaum 1996).\n\n2.3 Fairness and discrimination in information systems\n\nLeventhal (1980) describes fairness as equal treatment based on people’s\n\nperformance and needs. Table 1 offers an overview of the different fairness\n\ndefinitions. Individual fairness means that, independent of group membership, two\n\nindividuals who are perceived to be similar by the measures at hand should also be\n\ntreated similarly (Dwork et al. 2012). Rising from the micro-level onto the meso-\n\nlevel, Dwork et al. (2012) also proposed another measure of fairness, that is, group\n\nfairness, in which entire (protected) groups of people are required to be treated\n\nsimilarly (statistical parity). Hardt et al. (2016) extended these notions by including\n\ntrue outcomes of predicted variables to achieve fair treatment. In their sense, false-\n\nBusiness Research (2020) 13:795–848 801\n\n123\n\n\n\npositives/negatives are sources of disadvantage and should be equal among groups\n\nmeans equal opportunity for false-positives/negatives (Hardt et al. 2016).\n\nUnfair treatment of certain groups of people or individual subjects yields to\n\ndiscrimination. Discrimination is defined as the unequal treatment of different\n\ngroups (Arrow 1973). Discrimination is very similar to unfairness. Discriminatory\n\ncategories can be strongly correlated with non-discriminatory categories, such as\n\nage (i.e., discriminatory) and years of working experience (non-discriminatory)\n\n(Persson 2016). Also, there is a difference between implicit and explicit\n\ndiscrimination. Implicit discrimination is based on implicit attitudes or stereotypes\n\nand often unintentional (Bertrand et al. 2005). In contrast, explicit discrimination is\n\na conscious process due to an aversion to certain groups of people. In HR\n\nrecruitment and HR development, discrimination means the not-hiring or support of\n\na person due to characteristics not related to that person’s productivity in the current\n\nposition (Frijters 1998).\n\nThe HR literature, especially the literature on personnel selection, is concerned\n\nwith fairness in hiring decisions, because every selection measure of individual\n\ndifferences is inevitably discriminatory (Cascio and Aguinis 2013). However, the\n\nquestion arises ‘‘whether the measure discriminates unfairly’’ (Cascio and Aguinis\n\n2013, p. 183). Hence, the actual fairness of prediction systems needs to be tested\n\nbased on probabilities and estimates, which we refer to as objective fairness. In the\n\nselection context, the literature distinguishes between differential validity (i.e.,\n\ndifferences in subgroup validity) and differential prediction (i.e., differences in\n\nslopes and intercepts of subgroups), and both might lead to biased results (Meade\n\nand Fetzer 2009; Roth et al. 2017; Bobko and Bartlett 1978).\n\nIn HR recruitment and HR development, both objective fairness and subjective\n\nfairness perceptions of applicants and employees about the usage of algorithmic\n\ndecision-making need to be considered. In this regard, perceived fairness or justice\n\nis more a subjective and descriptive personal evaluation rather than an objective\n\nreality (Cropanzano et al. 2007). Subjective fairness plays an essential role in the\n\nrelationship between humans and their employers. Previous studies showed that the\n\nTable 1 Definitions of fairness\n\nName Author Definition\n\nIndividual\n\nfairness\n\nDwork et al.\n\n(2012)\n\n‘‘Similar’’ subjects should have ‘‘similar’’ classifications\n\nGroup\n\nfairness\n\nSubjects in protected and unprotected groups have an equal probability\n\nof being assigned positive\n\nP bY ¼ 1\n� �\n\n�\n\n�G ¼ 1Þ ¼ Pð bY ¼ 1jG ¼ 0Þ\n\nEqual\n\nopportunity\n\nHardt et al.\n\n(2016)\n\nFalse-negative rates should be equal\n\nP bY ¼ 0\n� �\n\n�\n\n�Y ¼ 1;G ¼ 1Þ ¼ Pð bY ¼ 0jY ¼ 1;G ¼ 0Þ\n\nY 2 0; 1f g is a random variable describing, e.g., the recidivism of a subject, bY its estimator and G 2\nf0; 1g; describes whether a subject is a member of a certain protected group (G ¼ 1Þ or not ðG ¼ 0Þ\n\n802 Business Research (2020) 13:795–848\n\n123\n\n\n\nlikelihood of conscientious behavior and altruisms is higher for employees who feel\n\ntreated fairly (Cohen-Charash and Spector 2001). Conversely, unfairness can have\n\nconsiderable adverse consequences. For example, in the recruitment context,\n\nfairness perceptions of candidates during the selection process have important\n\nconsequences for decision to stay in the applicant pool or accept a job offer (Bauer\n\net al. 2001). Therefore, it is crucial to know how people feel about algorithmic\n\ndecision-making taking over managerial decisions formerly made by humans, since\n\nthe fairness perceptions during the recruitment process and/or training process have\n\nessential and meaningful effects on attitudes, performance, morale, intentions, and\n\nbehavior (e.g., the acceptance or rejection of a job offer or job turnover, job\n\ndissatisfaction, and reduction or elimination of conflicts) (Gilliland 1993; McCarthy\n\net al. 2017; Hausknecht et al. 2004; Cropanzano et al. 2007; Cohen-Charash and\n\nSpector 2001). Moreover, negative experiences might damage the employer�s\nimage. Several online platforms offer the possibility of rating companies and their\n\nrecruitment and development process (Van Hoye 2013; Woods et al. 2020).\n\nConsidering justice and fairness in the organizational context (Gilliland 1993),\n\nthere are three core dimensions of justice: distributive, procedural, and interactional.\n\nThe three dimensions tend to be correlated. Distributive justice deals with the\n\noutcome that some humans receive and some do not (Cropanzano et al. 2007). Rules\n\nthat can lead to distributive justice are ‘‘[…] equality (to each the same), equity (to\n\neach in accordance with contributions, and need (to each in accordance with the\n\nmost urgency)’’ (Cropanzano et al. 2007, p. 37). To some extent, especially\n\nconcerning equity, this can be connected with individual fairness and group fairness\n\nfrom Dwork et al. (2012) and equal opportunities from Hardt et al. (2016).\n\nProcedural justice means that the process is consistent with all humans, not\n\nincluding bias, accurate, and consistent with the ethical norms (Cropanzano et al.\n\n2007; Leventhal 1980). Consistency plays an essential role in procedural justice,\n\nmeaning that all employees and all candidates need to receive the same treatment.\n\nAdditionally, the lack of bias, accuracy, representation of all parties, correction, and\n\nethics play an important role in achieving a high procedural justice (Cropanzano\n\net al. 2007). In contrast, interactional justice is about the treatment of humans,\n\nmeaning the appropriateness of the treatment from another member of the company,\n\nthe treatment with dignity, courtesy, and respect, and informational justice (share of\n\nrelevant information) (Cropanzano et al. 2007).\n\nIn general, algorithmic decision-making increases the standardization of\n\nprocedures, so that decisions should be more objective and less biased, and errors\n\nshould occur less frequently (Kaibel et al. 2019), since information processing by\n\nhuman raters can be unsystematic, leading to contradictory and insufficient\n\nevidence-based decisions (Woods et al. 2020). Consequently, procedural justice and\n\ndistributive justice are higher using algorithmic decision-making, because the\n\nprocess is more standardized, which still not means that it is without bias.\n\nHowever, especially in the context of an application or an employee evaluation, it\n\nis not only about how fair the procedure itself is (according to fairness measures),\n\nbut it is also about how people involved in the decision process perceive the fairness\n\nof the whole process. Often the personal contact, which characterizes the\n\nBusiness Research (2020) 13:795–848 803\n\n123\n\n\n\ninteractional fairness, is missing when using algorithmic decision-making. It is\n\ndifficult to fulfill all three fairness dimensions.\n\n3 Methods\n\nThis systematic literature review aims at offering a coherent, transparent, and\n\nreliable picture of existing knowledge and providing insights into fruitful research\n\navenues about the discrimination potential and fairness when using algorithmic\n\ndecision-making in HR recruitment and HR development. This is in line with other\n\nsystematic literature reviews that organize, evaluate, and synthesize knowledge in a\n\nparticular field and provide an overall picture of knowledge and suggestions for\n\nfuture research (Petticrew and Roberts 2008; Crossan and Apaydin 2010; Siddaway\n\net al. 2019). To this end, we followed the systematic literature review approach\n\ndescribed by Siddaway et al. (2019) and Gough et al. (2017) to ensure a methodical,\n\ntransparent, and replicable approach.1\n\n3.1 Search terms and databases\n\nWe engaged in an extensive keyword searching, which we derived in an iterative\n\nprocess of search and discussion between the two authors of this study (see\n\n‘‘Appendix’’ for the employed keywords). According to our research question, we\n\nfirst defined individual concepts to create search terms. We considered different\n\nterminology, including synonyms, singular/plural forms, different spellings, broader\n\nvs. narrow terms, and classification terms of databases to categorize contents\n\n(Siddaway et al. 2019) (see Table 2 for a complete list of employed keywords and\n\nsearch strings). Our priority was to achieve the balance between sensitivity and\n\nspecificity to get broad coverage of the literature and to avoid the unintentional\n\nomission of relevant articles (Siddaway et al. 2019).\n\nAs the first source of data, we used the social science citation index (SSCI) to\n\nensure broad coverage of scholarly literature. This database covers English-\n\nlanguage peer-reviewed journals in business and management. As part of the Web\n\nof Knowledge, the database includes all journals with an impact factor, which is a\n\nreasonable proxy for the most important publications in the field. We completed our\n\nsearch with the EBSCO Business Source Premier database to add further breadth.\n\nSince electronic databases are not fully comprehensive, we additionally searched in\n\nthe reference section of the considered papers and manually searched for articles\n\n(Siddaway et ",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmRhdGEuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9LJUMzJUI2Y2hsaW5nLVdlaG5lcjIwMjBfQXJ0aWNsZV9EaXNjcmltaW5hdGVkQnlBbkFsZ29yaXRobUFTeXMucGRm0",
      "keyphrases": [
        "systematic review",
        "algorithmic decision-making",
        "HR recruitment",
        "HR development",
        "discrimination",
        "fairness",
        "context"
      ],
      "title": "Discriminated by an algorithm: a systematic review of discrimination and fairness by algorithmic decision-making in the context of HR recruitment and HR development",
      "author": "Alina Köchling "
    },
    {
      "@search.score": 2.2315629,
      "content": "\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 \nDOI 10.1186/s40493-015-0019-z\n\nRESEARCH Open Access\n\nToward a testbed for evaluating\ncomputational trust models: experiments\nand analysis\nPartheeban Chandrasekaran and Babak Esfandiari*\n\n*Correspondence:\nbabak@sce.carleton.ca\nDepartment of Systems and\nComputer Engineering, Carleton\nUniversity, 1125 Colonel By Drive,\nOttawa, Ontario K1s5B6, Canada\n\nAbstract\nWe propose a generic testbed for evaluating social trust models and we show how\nexisting models can fit our tesbed. To showcase the flexibility of our design, we\nimplemented a prototype and evaluated three trust algorithms, namely EigenTrust,\nPeerTrust and Appleseed, for their vulnerabilites to attacks and compliance to various\ntrust properties. For example, we were able to exhibit discrepancies between\nEigenTrust and PeerTrust, as well as trade-offs between resistance to slandering attacks\nversus self-promotion.\n\nKeywords: Trust testbed; Reputation; Multi-agent systems\n\nIntroduction\nMotivation\n\nWith the growth of online community-based systems such as peer-to-peer file-sharing\napplications, e-commerce and social networking websites, there is an increasing need to\nprovide computational trust mechanisms to determine which users or agents are honest\nand which ones are malicious. Many models calculate trust by relying on analyzing a\nhistory of interactions. The calculations can range from the simple averaging of ratings\non eBay to flow-based scores in the Advogato website. Thus for a researcher to evaluate\nand compare his or her latest model against existing ones, a comprehensive test tool is\nneeded. However, our research shows that the tools that exist to assist researchers are not\nflexible enough to include different trust models and their evaluations. Moreover, these\ntools use their own set of application-dependent metrics to evaluate a reputation system.\nThis means that a number of trust models cannot be evaluated for vulnerabilities against\ncertain types of attacks. Thus, there is still a need for a generic testbed to evaluate and\ncompare computational trust models.\n\nOverview of our solution and contributions\n\nIn this paper, we present a model and a testbed for evaluating a family of trust algo-\nrithms that rely on past transactions between agents. Trust assessment is viewed as a\nprocess consisting of a succession of graph transformations, where the agents form the\nvertices of the graph. The meaning of the edges depends on the transformation stage,\n\n© 2015 Chandrasekaran and Esfandiari. Open Access This article is distributed under the terms of the Creative Commons\nAttribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution,\nand reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\nthe Creative Commons license, and indicate if changes were made.\n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s40493-015-0019-z-x&domain=pdf\nmailto: babak@sce.carleton.ca\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 2 of 27\n\nand can refer to the presence of transactions between the two agents or the existence\nof a trust relationship between them. Our first contribution is to show that with this\nview, existing reputation systems can be adopted under a single model, but they work at\ndifferent stages of the trust assessment workflow. This allows us to present a new classi-\nfication scheme for a number of trust models based on where they fit in the assessment\nworkflow. The second contribution of our work is that this workflow can be described\nformally, and by doing this, we show that it is possible to model a variety of attacks\nand evaluation schemes. Finally, out of the larger number of systems we classified, we\nselected three reputation systems, namely EigenTrust [1], PeerTrust [2] and Appleseed\n[3], to exemplify the range and variety of reputation systems that our testbed can accom-\nmodate. We evaluated these three systems in our testbed against simple attacks and\nwe validated their compliance to basic trust properties. In particular, we were able to\nexhibit differences in the way EigenTrust and PeerTrust rank the agents, we observed\nthe subtle interplay between slandering and self-promoting attacks (higher sensitivity\nto one attack can lead to lower sensitivity to the other), and we verified that trust\nweakens along a friend-of-a-friend chain and that it is more easily lost than gained\n(as it should be).\n\nOrganization\n\nThis article is organized as follows: section ‘Background and literature review’ provides\nbackground and state of the art on trust models, attacks against them, and existing\ntestbeds for evaluation. Section ‘Problem description and model’ formulates the research\nproblem of this article and proposes our model for a testbed. Section ‘Classifying and\nchaining algorithms’ shows how some of existing trust algorithms can fit our model, and\nhow one can combine or compare them using our model and testbed. Section ‘Results and\ndiscussion’ describes the implementation details of our testbed prototype and presents\nevaluation results of three different trust algorithms, namely EigenTrust, PeerTrust, and\nAppleseed. Section ‘Conclusions’ concludes this article and summarizes the contributions\nand limitations of our work.\n\nBackground and literature review\nSocial trust models\n\nTrust management systems aid agents in establishing and assessing mutual trust. How-\never, the actual mechanisms used in these systems vary. For example, public key infras-\ntructures [4] rely on certificates whereas reputation-based trust management systems are\nbased on experiences of earlier direct and indirect interactions [5].\nIn this paper we will focus on social trust models based on reputation. The trust model\n\nshould provide a means to compare the trustworthiness of agents in order to choose a\nparticular agent to perform an action. For instance, on an e-commerce website like eBay,\nwe need to be able to compare the trustworthiness of sellers in order to pick the most\ntrustworthy one to buy a product from.\nSocial trust models rely on past experiences of agents to produce trust assertions. That\n\nis, the agents in the system interact with each other and record their experiences, which\nare then used to determine whether a particular agent is trustworthy. This model is self-\nsufficient because it does not rely on a third party to propagate trust, like it would in\ncertificate authority-based PKI trust models. However, there are drawbacks to having no\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 3 of 27\n\nroot of trust. For instance, agents evaluating the trustworthiness of agents with whom\nthere has been no interaction must use recommendations from others and, in turn,\nevaluate the trustworthiness of the recommenders. Social trust models must address this\nproblem.\n\nNature of input\n\nVarious inputs are used by social trust algorithms to measure the trustworthiness of\nagents. In EigenTrust [1], PeerTrust [2], TRAVOS [6] and Beta Reputation System (BRS)\n[7], agents rate their satisfaction after a transaction (e.g., downloading a file in a P2P\nfile-sharing network). These ratings are used to obtain a trust score that represents the\ntrustworthiness of the agent. In Aberer and Despotovic’s system [5]1, agents may file com-\nplaints (can be seen as dissatisfaction) about each other after a transaction. In Advogato\n[8], whose goal is to discourage spam on its blogging website, users explicitly certify\neach other as belonging to a particular level in the community. Trust algorithms may\nalso directly use trust scores among agents to compute an aggregated trustworthiness\nof agents, as in TidalTrust [9] and Appleseed [3]. In the specific context of P2P file-\nsharing, Credence [10] uses the votes on file authenticity to calculate a similarity score\nbetween agents and uses it to measure trust. The trust score is then used to recommend\nfiles.\n\nDirect vs. indirect trust\n\nThe truster may use some or all of its own and other agents’ past experiences with the\ntrustee to obtain a trust score. Trust algorithms often use gossiping to poll agents with\nwhom the truster has had interactions in the past.\nThe trust score calculated using only the experiences from direct interactions is\n\ncalled the direct trust score, while the trust score calculated using the recommenda-\ntions from other agents is called the indirect trust score [11]. As mentioned earlier,\nreputation systems use different inputs (satisfaction ratings, votes, certificates, etc.) to\ncalculate direct trust scores and indirect trust scores. PeerTrust uses satisfaction ratings\nto calculate both direct and indirect trust scores, whereas EigenTrust and TRAVOS\nuse satisfaction ratings to calculate direct trust scores, which they then use to calcu-\nlate indirect trust scores. Therefore, we can categorize the trust algorithms based on\nthe input required. But how do trust algorithms calculate the trust scores of agents\nusing the above information? It again varies from algorithm to algorithm. For instance,\nPeerTrust, EigenTrust, and Aberer use simple averaging of ratings, TRAVOS and BRS\nuse the beta probability density function, and Appleseed uses the Spreading Activation\nmodel.\n\nGlobal vs. local trust\n\nThe trust algorithm may output a global trust score or a local trust score [3, 12]. A global\ntrust score is one that represents the general trust that all agents have on a particular\nagent, whereas local trust scores represents the trust from the perspective of the truster\nand thus each truster may trust an agent differently. In our survey, we found PeerTrust,\nEigenTrust, and Aberer to be global trust algorithms whereas TRAVOS, BRS, Credence,\nAdvogato, TidalTrust, Appleseed, Marsh [13] and Abdul-Rahman [14] are local trust\nalgorithms.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 4 of 27\n\nTo trust or not to trust\n\nOnce the trust score is calculated, it can be used to decide whether to trust the agent. It\ncan be as simple as comparing the trust score against a threshold: if the trust score is above\na certain threshold, then the agent is trusted. Marsh [13], and Aberer [5] use thresholding\ntechniques. If the trust algorithm outputs normalized trust scores of agents as in Eigen-\nTrust, then the trust scores of agents are ranked. In this case, one may consider a certain\npercentage of the top ranked agents as trustworthy. In Appleseed, a graph is first obtained\nwith trust scores of agents as edge weights, and then, the truster agent is “injected” with\na value called the activation energy. This energy is spread to agents with a spreading fac-\ntor along the edges in the graph and the algorithm ranks the agents according to their\ntrust scores. Trust decisions can also be flow-based such as in Advogato, which calculates\na maximum “flow of trust” in the trust graph to determine which agents are trustworthy\nand which are not.\nIn short, social trust models focus on the following:\n\n1. What is the input to calculate the trust score of an agent?\n2. Does the trust algorithm use only direct experience or does it also rely on third\n\nparty recommendations?\n3. Is the trust score of an agent global or local?\n4. How does one decide whether to trust an agent?\n\nGiven the above discussion, and to assess the scope of our testbed, we propose tomodel,\nevaluate and compare three algorithms from fairly different families. The next sections\nprovide detailed descriptions of the trust models we selected and that we implemented in\nour testbed. The details are given to help understand the output of our experiments, but\nreaders familiar with EigenTrust, PeerTrust and/or AppleSeed may skip those respective\nsections.\n\nPeerTrust\n\nIn PeerTrust, agents rate each other in terms of the satisfaction received. These ratings\nare weighted by trust scores of the raters, and a global trust score is computed recursively\nusing Eq. 2.1, where:\n\n• T(u) is the trust score of agent u\n• I(u) is the set of transactions that agent u had with all the agents in the system\n• S(u, i) is the satisfaction rating on u for transaction i\n• p(u, i) is the agent that provided the rating.\n\nT(u) =\nI(u)∑\ni=1\n\nS(u, i) × T(p(u, i))∑I(u)\nj=1 T(p(u, j))\n\n(2.1)\n\nPeerTrust also provides a method for calculating local trust scores. In both local and\nglobal trust score computations, the trust score is compared against a threshold to decide\nwhether to trust or not.\n\nEigenTrust\n\nAgents in EigenTrust rate transactions as satisfactory or unsatisfactory [1]. These trans-\naction ratings are used as input, to calculate a local direct trust score, from which a global\ntrust score is then calculated.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 5 of 27\n\nAn agent i calculates the normalized local trust score of agent j, as shown in Eq. 2.2,\nwhere tij ∈ {+1,−1} is the transaction rating, and sij is the sum of ratings.\n\nsij =\n∑\nTij\n\ntrij\n\ncij = max(sij, 0)∑\nk max(sik , 0)\n\n(2.2)\n\nNote that we cannot use sij as the local trust score without normalizing, because mali-\ncious agents can arbitrarily assign high local trust values to fellow malicious agents and\nlow local trust values to honest agents.\nTo calculate the global trust score of an agent, the truster queries his friends for their\n\ntrust scores on the trustee. These local trust scores are aggregated, as shown in Eq. 2.3.\n\ntik =\n∑\nj\ncijcjk (2.3)\n\nIf we let C be the matrix containing cij elements, �ci be the local trust vector for i (each\nelement corresponds to the trust that i has in j), and �ti the vector containing tik , then,\n\n�ti = CT �ci (2.4)\n\nBy asking a friend’s friend’s opinion, Eq. 2.4 becomes �ti = (CT )2 �ci. If an agent keeps\nasking the opinions of its friends of friends, the whole trust graph can be explored, and\nEq. 2.4 becomes Eq. 2.5, where n is the number of hops from i.\n\n�t = (CT )n �ci (2.5)\n\nThe trust scores of the agents converge to a global value irrespective of the trustee.\nBecause EigenTrust outputs global trust scores (normalized over the sum of all agents),\n\nagents are ranked according to their trust scores (unlike PeerTrust). Therefore, an agent\nis considered trustworthy if it is within a certain rank.\n\nAppleseed\n\nAppleseed is a flow-based algorithm [3]. Assuming that we are given a directed weighted\ngraph with agents as nodes, edges as trust relationships, and the weight of an edge as\ntrustworthiness of the sink, we can determine the amount of trust that flows in the graph.\nThat is, given a trust seed, an energy in ∈ R\n\n+\n0 , spreading factor decay ∈[ 0, 1], and conver-\n\ngence threshold Tc, Appleseed returns a trust score of agents from the perspective of the\ntrust seed.\nThe trust propagation from agent a to agent b is determined using Eq. 2.6, where the\n\nweight of edge (a, b) represents the amount of trust a places in b, and in(a) and in(b)\nrepresent the flow of trust into a and b, respectively.\n\nin(b) = decay ×\n∑\n\n(a,b)∈E\nin(a) × weight(a, b)∑\n\n(a,c)∈E weight(a, c)\n(2.6)\n\nThe trust of an agent b (trust(b)) is then updated using Eq. 2.7, where the decay factor\nensures that trust in an agent decreases as the path length from the seed increases.\n\ntrust(b) := trust(b) + (1 − decay) × in(b) (2.7)\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 6 of 27\n\nGenerally, trust graphs have loops, which makes Eq. 2.7 recursive. Thus a termination\ncondition like the one below is required, where Ai ⊆ A is the set of nodes that were\ndiscovered until step i and trusti(x) is the current trust scores for all x ∈ Ai:\n\n∀x ∈ Ai : trusti(x) − trusti−1(x) ≤ Tc (2.8)\n\nAfter Eq. 2.7 terminates, the trust scores of agents are ranked. Since this set is ranked\nfrom the perspective of the seed, Appleseed is a local trust algorithm.\nAs our brief survey shows, the trust models vary in terms of their input, output, and\n\nthe methods they use. To evaluate and compare them, testbeds are needed. In the next\nsection we take a look at existing testbeds.\n\nTestbeds\n\nWe investigated two testbed models, namely Guha’s [15] andMacau [16], and two testbed\nimplementations, namely ART [17] and TREET [18], which are used to evaluate trust\nalgorithms. This section provides details of our investigation.\n\nGuha\n\nGuha [15] proposes a model to capture document recommendation systems, where trust\nand reputation play an important role. The model relies on a graph of agents where the\nedges can be weighted based on their mutual ratings, and a rating function for documents\nby agents. Guha then discusses how trust can be calculated based on those ratings, and\nevaluates a few case studies of real systems that can be accommodated by the model.\nGuha’s model can capture trust systems that take a set of documents and their ratings\n\nas input (such as Credence [10]), but it cannot accommodate systems where the only\ninput consists of direct feedbacks between agents, such as in PeerTrust (global) [2] or\nEigenTrust [1]. Also, the rating of documents is itself an output of Guha’s model, and that\nis often not the purpose or output of many more general-purpose trust models.\nIn short, document recommendation systems can be viewed as a specialization or\n\nsubclass of more general trust systems, and Guha’s model is suitable for that subclass.\n\nMacau\n\nHazard and Singh’s Macau [16] is a model for evaluating reputation systems. The authors\ndistinguish two roles for any agent: a rater that evaluates a target. Transactions are viewed\nas a favor provided by the target to the rater. The target’s reputation, local to each rater-\ntarget pairing, is updated after each transaction and depends on the previous reputation\nvalue. The target’s payoff in giving a favor is also dependent on its current reputation but\nalso on its belief of the likelihood that the rater will in turn return the favor in the future.\nBased on the above definitions, the authors define a set of desirable properties for a\n\nreputation system:\n\n• Monotonicity: given two different targets a and b, the computed reputation of a\nshould be higher than that of b if the predicted payoff of a transaction with a is\nhigher than with b.\n\n• Unambiguity and convergence: the reputation should converge over time to a single\nfixpoint, regardless of its initial value.\n\n• Accuracy: this convergence should happen quickly, thus minimizing the total\nreputation estimation errors in the meantime.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 7 of 27\n\nMacau thus captures an important stage in trust assessment, i.e. the update of one-to-\none trustworthiness based on past transactions. It has been used to evaluate, in terms of\ntheir compliance to the properties defined above, algorithms such as TRAVOS [6] and the\nBeta Reputation System (BRS) [7] that model positive and negative experiences as ran-\ndom variables following a beta probability distribution. The comparison of trust models\nrelying on the beta distribution and their resilience to various attacks has also recently\nbeen explored in [19].\n\nART\n\nThe Agent Reputation and Trust testbed (ART) [17] provides an open-source message-\ndriven simulation engine for implementing and comparing the performance of reputation\nsystems. ART uses art painting sales as the domain.\nEach client has to sell paintings belonging to a particular era. To determine their\n\nmarket values, clients refer to agents for appraisals for a fee. Because each agent\nis an expert only in a specific era, it may not be able to provide appraisals for\npaintings from other eras and therefore refers to other agents for a fee. After such\ninteractions, agents record their experiences, calculate their reputation scores, and\nuse them to choose the most trustworthy agents for future interactions. The goal\nof each agent is to finish the simulation with the highest bank balance, and, intu-\nitively, the winning agent’s trust mechanism knows the right agents to trust for\nrecommendations.\nThe ART testbed provides a protocol that each agent must implement. The protocol\n\nspecifies the possible messages that agents can send to each other. Themessages are deliv-\nered by the simulation engine, which loops over each agent at every time interval. The\nengine is also responsible for keeping track of the bank balance of the agents, and assign-\ning new clients to agents. All results are collected and stored in a database and displayed\non a graphical user interface (GUI) at runtime.\nART is best suited for evaluating trust calculation schemes from a first person point\n\nof view. It is not meant as a platform for testing trust management as a service provided\nby the system. For example, to evaluate EigenTrust in ART, one would either need to\nconsiderably modify ART itself (for the centralized version of EigenTrust) or to require\ncooperation from the participating agents and an additional dedicated distributed infras-\ntructure (for the distributed version). Furthermore, as also pointed out in [16] and [20],\nthe comparison of the performance of different agents is not necessarily based on their\ncorrect ability to assess the reputation of other agents, but rather based on how well they\nmodel and exploit the problem domain.\n\nTREET\n\nThe Trust and Reputation Experimentation and Evaluation Testbed (TREET) [18] mod-\nels a general marketplace scenario where there are buyers, sellers, and 1,000 different\nproducts with varying prices, such that there are more inexpensive items than expensive\nones. The sale price of the products is fixed, to avoid the influence of market competition.\nThe cost of producing an item is 75% of the selling price, and the seller incurs this cost.\nTo lower this cost and increase profit, a seller can cheat by not shipping the item. Each\nproduct also has a utility value of 110% of the selling price, which encourages buyers to\npurchase.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 8 of 27\n\nAgents join or exit after 100 simulation days or after a day with a probability of 0.05,\nbut to keep the number of buyers and sellers constant, an agent is introduced for each\ndeparting agent. At initialization, each seller is assigned a random number of products\nto sell. Buyers evaluate the offers from each seller and pick a seller. Sellers are informed\nof the accepted offers and are paid. Fourteen days after a sale, the buyer knows whether\nhe has been cheated or not, depending on whether he receives the purchased item. The\nbuyer then provides feedback based on his experience of the transaction. The feedback is\nin turn used to choose sellers for future transactions.\nTREET evaluates the performance of various reputation systems under Reputation Lag\n\nattack, Proliferation attack, and Value Imbalance attack using the following metrics:\n\n1. cheater sales over honest sales ratio\n2. cheater profit over honest profit ratio\n\nMultiple seller accounts are needed to orchestrate a Proliferation Attack, but TREET\ndoes not consider attacks such as White-Washing and Self-Promoting, which require\ncreating multiple buyer accounts.\nTREET addresses many of ART’s limitation in a marketplace scenario. To name a\n\nfew [21], TREET supports both centralized and decentralized trust algorithms, allows\ncollusion attacks to be implemented, and does not put a restriction on trust score rep-\nresentation. However, like ART, the evaluation metrics in TREET are tightly coupled to\nthe marketplace domain. It is unclear how ART or TREET can be used to evaluate trust\nmodels used in other systems, such as P2P file-sharing networks, online product review\nwebsites and others that use trust. To our knowledge, there is no testbed that provides\ngeneric evaluation metrics and that is independent of the application domain.\n\nSummary\n\nTrust is a tool used in the decision-making process and it can be computed. There are\nmanymodels based on social trust that attempt to aid agents in making rational decisions.\nHowever, these models vary in terms of their input and output requirements. This makes\nevaluations against a common set of attacks difficult.\n\nProblem description andmodel\nOur goal is to have a testbed that is generic enough to accommodate as many trust\nmanagement systems and models as possible. Our requirements are:\n\n1. A model that provides an abstraction layer for developers to incorporate existing\nand new systems that match the input and output of the model.\n\n2. An evaluation framework to measure and compare the performance of trust models\nagainst trust properties and attacks independently of the application domain.\n\nIn this section, we introduce an abstract model for trust management systems. This\nmodel will be the foundation of our testbed. Our model is essentially based on the\nfollowing stages:\n\n1. In stage 1 of the trust assessment process, the feedback provided by agents on other\nagents is represented as a feedback history graph.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 9 of 27\n\n2. In stage 2, a reputation graph is produced, where the weight of an arc denotes the\nreputation of the target agent. “Reputation” here follows [14], as “an expectation\nabout an individual’s behavior based on information about or observations of its\npast behavior”. It is viewed as an estimation of trustworthiness based on a\ncombination of direct and indirect feedback.\n\n3. In the final stage, a trust graph is produced, where the existence of an arc implies\ntrust in the target agent. We take “trust” here to mean the “belief by agent A that\nagent B is trustworthy” [2, 22], and so it is boolean and subjective in our model.\n\nIn the rest of this section, we define the aforementioned graphs in stages.\n\nStage 1—obtain feedback history graph\n\nWe first define a feedback, f (a, b) ∈ R as an assessment made by agent a of an action or\ngroup of actions performed by agent b, where a and b belong to the set A of all the agents\nin the system. The list of n feedbacks by a on b, FHG(a, b), is called a feedback history,\nrepresented as follows:\n\nFHG(a, b) �→ (f1(a, b), f2(a, b), . . . , fn(a, b)) (3.1)\n\nThe feedback fi(a, b) indicates the ith satisfaction received by a from b’s action. For\nexample, in a file-sharing network, the feedback by a downloader may indicate the sat-\nisfaction received from downloading a file from an uploader in terms of a value in R.\nExisting trust models use different ranges of values for feedback, and letting the feedback\nvalue be in R allows us to include these reputation systems in our testbed.\nIf A is the set of agents, E is the set of labelled arcs (a, b), and the label is FHG(a, b)\n\nwhen FHG(a, b) \t= ∅, then the feedback histories for all agents in A are represented in a\ndirected and labelled graph called Feedback History Graph (FHG)2, FHG = (A,E):\n\nFHG : A × A → R\nN\n\n∗\n(3.2)\n\nNote that we have not included timestamps associated with each feedback (which would\nbe useful for, among other things, running our testbed as a discrete event simulator), but\nour model can be expanded to accommodate it.\nOnce the feedback history graph is obtained, the next step is to produce a reputation\n\ngraph.\n\nStage 2—obtain reputation graph\n\nA Reputation Graph (RG), RG = (A,E′\n), is a directed and weighted graph, where the\n\nweight on an arc, RG(a, b), is the trustworthiness of b from a’s perspective:\n\nRG : A × A → R (3.3)\n\nThe edges are added by computing second and nth-hand trust via transitive closure of\nedges in E. That is: if (a, b) ∈ E and (b, c) ∈ E ⇒ (a, b), (b, c), and (a, c) ∈ E′ (the value of\nthe weight of the edges, however, depends on the particular trust algorithm).\nReputation algorithms may also exhibit the reflexive property by adding looping arcs to\n\nindicate that the truster trusts itself to a certain degree for a particular task [1–3].\nThe existing literature categorizes reputation algorithms into two groups: local and\n\nglobal (Figs. 1(a) and (b), respectively) [3, 5]. Global algorithms assign a single reputa-\ntion score to each agent. Therefore, if a global algorithm is used, then the weights of the\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 10 of 27\n\nFig. 1 Examples of reputation graphs output respectively by a local and global algorithm\n\nincoming arcs of an agent should be the same, as shown in Fig. 1(b) (although for clar-\nity’s sake we will often present the graph simply as a ranking of agents in the rest of this\narticle). There is no such property for local algorithms.\nReputation algorithms may also differ in how the graphs is produced. One method is\n\nto first calculate one-to-one scores of agents using direct feedbacks and then use them\nto calculate the trustworthiness of agents previously unknown to the truster (e.g., Eigen-\nTrust). This is shown as 1a and 1b in Fig. 2. The other method (#2 in Fig. 2) skips the\nintermediate graph in the aforementioned method and produces a reputation graph (e.g.,\nPeerTrust).\n\nStage 3—obtain trust graph\n\nThe graph obtained in stage 2 contains information about the trustworthiness of agents.\nBut to use this information to make a decision about a transaction in the future, agents\nmust convert trustworthiness to boolean trust (see [23] for an example), which can also\nbe expressed as a graph. We refer to this directed graph as the Trust Graph (TG) TG =\n(A, F), where a directed edge ab ∈ F represents agent a trusting agent b.\nTo summarize ourmodel, we can represent the stages as part of a workflow as illustrated\n\nin Fig. 3.\n\nFig. 2 Two methods to obtain a reputation graph\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 11 of 27\n\nFig. 3 Overview of the stages in our model\n\nIn the next section, we see at what stages in our model do various algorithms fit, and\ndescribe criteria for chaining different algorithms.\n\nClassifying and chaining algorithms\nBy refactoring the trust models according to the stages presented in the above sections,\nwe start to see a new classification scheme. Let us take EigenTrust, PeerTrust, and Apple-\nseed as examples and describe them using our model. EigenTrust takes an FHG with\nedge labels in {0, 1}∗ as input and outputs an RG with edge labels in [ 0, 1]. PeerTrust,\non the other hand, takes an FHG with edge labels in [ 0, 1]∗ as input and outputs an\nRG with edge labels in [ 0, 1]. Meanwhile, Appleseed requires an RG with edge labels in\n[ 0, 1] as input and outputs another RG′ in the same codomain. It is also possible for an\nalgorithm to skip some stages. For example, according to our model, Aberer [5] skips\nstage 2 and does not output a reputation graph. One can also represent simple mecha-\nnisms to generate a trust graph by applying a threshold on reputation values (as output\nfor example by EigenTrust), or by selecting the top k agents. This stage transitions of\nalgorithms are depicted3 in Fig. 4. In addition to the existing classification criteria in the\nstate of the art, trust algorithms can now be classified according to their stage transi-\ntions (i.e., from one stage to another as well as transitioning within a stage) as shown in\nTable 1.\nIt is important to note that although these three algorithms output a reputation\n\ngraph with continuous reputation values between 0 and 1, the semantics of these val-\nues are different. EigenTrust outputs relative (among agents) global reputation scores,\nPeerTrust outputs an absolute global reputation score, and Appleseed produces relative\nlocal reputation scores. In other words, EigenTrust and Appleseed are ranking algorithms\n(global and local, respectively), whereas PeerTrust is not.\n\n\n\nChandrasekaran and Esfandiari Journal of Trust Management  (2015) 2:8 Page 12 of 27\n\nFig. 4 Stage transitions of Trust algorithms\n\nAs we can see, each step of the trust assessment process can be viewed as a\ngraph transformation function, and we can use this functional view to easily describe\nevaluation mechanisms as well. Suppose an experimenter wants to compare PeerTrust\nand EigenTrust. The inputs and outputs of these algorithms are semantically different.\nTo match the input, we can use a function that discretizes continuous feedback values\n(f (a, b)) in [0, 1] to {-1, 1}, using some threshold t:\n\nTable 1 A classification for trust models\n\nStage Global or\nAbsolute or\n\nTrust Algorithm\nTransitions\n\nInput\nLocal\n\nRelative\nReputation Scores\n\nEigenTrust 0 → 2\nsatisfaction\n\nglobal relativeratings\n\nPeerTrust 0 → 2\nsatisfaction\n\nglobal absoluteratings\n\nAppleSeed 2 → 2\nreputation\n\nlocal absolutescores\n\nAberer & Despotovic 0 → 3 complaints global N/A\n\nAdvogato 3 → 3 certificates local N/A\n\nTRAVOS 0 → 2\nsatisfaction\n\nlocal absoluteratings\n\nRanking 2 → 3\nreputation\n\nN/A relatives",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmRhdGEuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zNDA0OTMtMDE1LTAwMTktei5wZGY1",
      "keyphrases": [
        "computational trust models",
        "testbed",
        "experiments",
        "analysis"
      ],
      "title": "Toward a testbed for evaluating computational trust models: experiments and analysis",
      "author": "Partheeban Chandrasekaran"
    },
    {
      "@search.score": 1.524675,
      "content": "\nRESEARCH Open Access\n\nA classification method for social\ninformation of sellers on social network\nHaoliang Cui1, Shuai Shao2* , Shaozhang Niu1, Chengjie Shi3 and Lingyu Zhou1\n\n* Correspondence: shaoshuaib@163.\ncom\n2China Information Technology\nSecurity Evaluation Center, Beijing\n100085, China\nFull list of author information is\navailable at the end of the article\n\nAbstract\n\nSocial e-commerce has been a hot topic in recent years, with the number of users\nincreasing year by year and the transaction money exploding. Unlike traditional e-\ncommerce, the main activities of social e-commerce are on social network apps. To\nclassify sellers by the merchandise, this article designs and implements a social\nnetwork seller classification scheme. We develop an app, which runs on the mobile\nphones of the sellers and provides the operating environment and automated\nassistance capabilities of social network applications. The app can collect social\ninformation published by the sellers during the assistance process, uploads to the\nserver to perform model training on the data. We collect 38,970 sellers’ information,\nextract the text information in the picture with the help of OCR, and establish a\ndeep learning model based on BERT to classify the merchandise of sellers. In the\nfinal experiment, we achieve an accuracy of more than 90%, which shows that the\nmodel can accurately classify sellers on a social network.\n\nKeywords: User model, Machine learning, Social e-commerce\n\n1 Introduction\nWith the continuous improvement of social network and mobile payment technology,\n\none kind of commodity trading based on social relations called social e-commerce is in\n\nrapid development. According to the 2019 China social e-commerce industry develop-\n\nment report released by the Internet society of China, the number of employees of so-\n\ncial e-commerce in China is expected to reach 48.01 million in 2019, up by 58.3\n\npercent year on year, and the market size is expected to reach 2060.58 billion yuan, up\n\nby 63.2% year on year. Social e-commerce has become a large scale, and the high\n\ngrowth cannot be ignored. Different from e-commerce platforms such as Taobao, so-\n\ncial e-commerce is at the end of online retail. It carries out trading activities through\n\nsocial software and uses social interaction, user generated content and other means to\n\nassist the purchase and sale of goods. At the same time, sellers on social network use\n\ndifferent social software without uniform registration, have no systematic classification\n\nof products for sale, and there are no standardized terms for product description.\n\nThese bring great difficulty to the accurate classification of user portrait. This paper\n\nproposes a method based on the NLP classification model, which can realize accurate\n\n© The Author(s). 2021 Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the\noriginal author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or\nother third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit\nline to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by\nstatutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a\ncopy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n\nEURASIP Journal on Image\nand Video Processing\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 \nhttps://doi.org/10.1186/s13640-020-00545-z\n\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s13640-020-00545-z&domain=pdf\nhttp://orcid.org/0000-0001-9638-0201\nmailto:shaoshuaib@163.com\nmailto:shaoshuaib@163.com\nhttp://creativecommons.org/licenses/by/4.0/\n\n\nbusiness classification of social e-commerce based on social information of social e-\n\ncommerce. This method analyzes 38,970 sellers on social networks and establishes a\n\ndeep learning model based on BERT to accurately classify the merchandise of sellers.\n\nIn addition, we introduced the OCR algorithm to extract the text information in the\n\npicture and superimposed it on the social content data, which effectively improved the\n\nclassification accuracy. The final experiment shows that the measured accuracy is more\n\nthan 90%.\n\n2 Related work\n2.1 Natural language processing\n\nIn order to analyze e-commerce business classification based on social data of sellers on a\n\nsocial network, the text needs to be analyzed based on the NLP correlation algorithm.\n\nThe rapid development of NLP at the present stage is due to the neural network language\n\nmodel (NNLM) Bengio et al. [1] proposed in 2003. Researchers have been trying to realize\n\nthe end-to-end classification recognition by using a neural network as a classifier in the\n\ntext classification research based on word embedding. Kim first introduces the convolu-\n\ntional neural network (CNN) into the study of text classification. The network structure is\n\na dropout full connection layer and a softmax layer connected after one convolution layer\n\n[2]. Although this algorithm achieves good results in various benchmark tests, it cannot\n\nobtain long-distance text dependency due to the limitation of network structure. There-\n\nfore, Tencent AI Lab proposed DPCNN, which further enhanced the extraction capacity\n\nof long-distance text dependency by deepening CNN [3].\n\nSocial content data includes multimedia text data and picture data. With the help of\n\nOCR, we extract the text in the picture and convert the picture data into text data. Text\n\nis a kind of sequential data, and the classification of it by recurrent neural network\n\n(RNN) has been the focus of long-term research in academia [4]. As a variation of\n\nRNN, long short-term memory (LSTM) adds control units such as forgetting gate, in-\n\nput gate, and output gate on the original basis, which solves the problem of gradient\n\nexplosion and gradient disappearance in the long sequence training of RNN and pro-\n\nmotes the use of RNN [5]. By introducing the sharing information mechanism, Liu\n\net al. further improved the accuracy of the RNN algorithm in the text multi-\n\nclassification task and achieved good results in four benchmark text classifications [6].\n\nHowever, Word vectors cannot be constructed in Word embedding to solve the\n\nproblem of polysemy. Even though different semantic environments are considered\n\nduring training, the result of training is still one word corresponding to one row vector.\n\nConsidering the widespread phenomenon of polysemy, Peters et al. propose embed-\n\ndings from language model (ELMO) to address the impact of polysemy on natural lan-\n\nguage modeling [7]. ELMO uses a feature-based form of pre-training. First, two-way\n\nLSTM is used to pre-train the corpus, and then word embedding resulting from train-\n\ning is adjusted by double-layer two-way LSTM when processing downstream tasks to\n\nadd more grammatical and semantic information according to the context words.\n\nThe ability of ELMO to extract features is limited for choosing LSTM as the feature\n\nextractor instead of Transformer [8], and ELMO’s bidirectional splicing method is also\n\nweak in feature fusion. Therefore, Devlin et al. propose the BERT model, taking Trans-\n\nformer as a feature extractor to pre-train large-scale text corpus [9].\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 2 of 12\n\n\n\n2.2 User analysis of social networks\n\nUser analysis is an important part of social network analysis. Most existing studies use\n\nuser-generated content or social links between users to simulate users. Wu et al. mod-\n\neled users on the content curation social network (CCSN) in the unified framework by\n\nmining user-generated content and social links [10]. They proposed a potential Bayes-\n\nian model, multilevel LDA (MLLDA), that could represent users of potential interest\n\nfound in social links formed by text descriptions contributed by users and information\n\nsharing. In 2017, Wu et al. proposed a latent model [11], trying to explain how the so-\n\ncial network structure and users’ historical preferences change over time affect each\n\nuser’s future behavior and predict each user’s consumption preferences and social con-\n\nnections in the near future. Malli et al. proposed a new online social network user pro-\n\nfile rating model [12], which solved the problem of large and complicated user data. In\n\nterms of data analysis platform, Chen et al. [13] developed a big data platform for the\n\nstudy of the garlic industry chain. Garlic planting management, price control, and pre-\n\ndiction were realized through data collection, storage, and pretreatment. Ning et al.\n\n[14] designed a ga-bp hybrid algorithm based on the fuzzy theory and constructed an\n\nair quality evaluation model by combining the knowledge of BP neural network, genetic\n\nalgorithm, and fuzzy theory. Yin et al. [15] studied two methods of extracting supervis-\n\nory relations and applied them to the field of English news. One is the combination of\n\nsupport vector machine and principal component analysis, and the other is the combin-\n\nation of support vector machine and CNN, which can extract high-quality feature vec-\n\ntors from sentences of support vector machine. In the social apps, the data we obtain is\n\nmostly image data, so we introduced the OCR technology to identify text information\n\nin images.\n\n3 Data collection\nIn order to analyze the behavior patterns of social e-commerce, we developed an auxil-\n\niary tool for social e-commerce. In this tool, sellers on a social network are provided\n\nwith the independent running environment of social software and the automatic auxil-\n\niary ability, and the information acquisition module of the auxiliary process is used to\n\ncollect the social information published by sellers on a social network, which is\n\nuploaded to the background server for model training. We provided this tool to nearly\n\n10,000 sellers on a social network who participated in the experiment to obtain their\n\nsocial information in their e-commerce activities.\n\n3.1 Overall structure\n\nThe whole data collection scheme is mainly composed of two parts: intelligent space\n\napp and background server. The overall architecture is shown in Fig. 1. Intelligent\n\nspace app is deployed in the mobile phones of sellers on a social network and imple-\n\nmented based on the application layer of the Android platform, providing sellers on a\n\nsocial network with a secure container for the independent operation of social software.\n\nThe app contains the automatic assistant module, which provides the automatic assist-\n\nant capability of various business processes for seller, and collects the social informa-\n\ntion in the auxiliary process through the information grasping module. The collected\n\ninformation is cached and uploaded locally through the information collection service.\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 3 of 12\n\n\n\nThe background server is responsible for receiving the collected data uploaded by the\n\nintelligent space, preprocessing the data first, and then classifying the social e-\n\ncommerce through the data based on the machine learning classification model, and fi-\n\nnally storing the classification results.\n\n3.1.1 Security container\n\nThe security container is designed to allow social software to run independently with-\n\nout modifying the OS or gaining root privileges. The basic principle of its realization is\n\nto create an independent container process; load APK file of social software dynamic-\n\nally; monitor and intercept process communication interface such as Binder IPC\n\nthrough Libc hook, Java reflection, dynamic proxy, and other technical means; and col-\n\nlect social information through an automatic assistant module. The main part of the\n\ncontainer is composed of an application layer module and a service layer module.\n\nThe application layer module is responsible for the process startup and execution of\n\nsocial software, and its main functions include three parts.\n\n3.1.1.1 Interactive interception The application layer module intercepts the inter-\n\naction between the application process and the underlying system in the container and\n\nmodifies the calling logic. By hook or dynamic proxy of system library API and Binder\n\ncommunication interface, the application layer module blocks all interfaces that interact\n\nwith the system during the execution of social software and controls the process\n\nboundary of interaction between social applications and system services.\n\n3.1.1.2 Social information collection The loading of the automatic auxiliary module\n\nby social software is realized when initializing the process of social application.\n\nThe application layer module injects the corresponding plugins in the automatic\n\nassistant module into the social application process. The automatic assistance mod-\n\nule provides a number of e-commerce auxiliary functions for sellers on a social\n\nnetwork, including customer acquisition, social customer relationship management\n\nLinux Kernel\n\nBinder Mode\n\nIntelligent Space\n\nService Layer Mode\nAMS Proxy PMS Proxy\n\nApplication Layer Mode\nSocial App\n\nInteractive \ninterception\n\nautomatic \nassistance  \nmodule\n\nInformation\nCollection \n\nBinder IPC\n\nBinder IPC\n\nBinder \nIPC Backgroud\n\n Server\n\nInternet\n\nFig. 1 The overall architecture diagram of the data acquisition scheme\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 4 of 12\n\n\n\n(SCRM), group management, sales assistance, and daily affairs. Sellers on social\n\nnetworks publish social information with commercial attributes through auxiliary\n\nfunctions, then the automatic auxiliary module will automatically collect the social\n\ninformation and send it to the information collection service for processing.\n\n3.1.1.3 Local processing of social information When the information collection ser-\n\nvice receives the social information collected by the automatic auxiliary module, the\n\ndata will be compressed and encrypted in the local cache. The service then uploads the\n\ncollected data to the background server periodically through the timer, and HTTPS is\n\nused to ensure data transmission security.\n\nThe main function of the service layer module is to take over the call logic modified\n\nby the application layer module by simulating the system service modify the parameters\n\nin the communication process and finally call the real system service. The service layer\n\nmodule exists in the container as an independent process. It focuses on the simulation\n\nof activity manager service (AMS) and package manager service (PMS) and realizes the\n\nsupport of system services in the process of launching and running social software.\n\n3.1.2 Background server\n\nThe background server mainly realizes the machine learning model processing of the\n\ncollected social data, including the functions of data preprocessing, data training, classi-\n\nfication, and result storage. The core processing logic will be described in chapter 5.\n\n3.2 Key processes\n\nThere are four key processes in the process of social information collection and pro-\n\ncessing. They are social software process initialization, social software process\n\nIntelligent \nSpace App \nlaunched\n\nProcess Boundaries\n\nUser Process\n\nSocial software process \ninitialization\n\nlaunching social \nsoftware\n\ninject automatic \nauxiliary\n\nSocial software process \nexecution\n\nRun the plug-in\n\nCollect social \ninformation\n\nProcess Boundaries\n\nUser Process\n\nLocal processing of \nsocial information\n\nBatch upload \nprocessed social \n\ninformation\n\nEncrypt, compress \nand store social \n\ninformation\n\nInternet\n\nInformation collecting \nservice process\n\nBackground processing \nof social information\n\nReceiving social \ninformation\n\nPreprocessing social \ninformation\n\nThe Server\n\nMachine learning \ncategorizes social \n\ninformation\n\nStore the \nclassification results\n\nFig. 2 Key flow chart of data acquisition scheme\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 5 of 12\n\n\n\nexecution, local processing of social information, and background processing of social\n\ninformation. The complete process is shown in Fig. 2.\n\n3.2.1 Social software process initialization\n\nWhen launching social software, the intelligent space will first intercept the callback\n\nfunction of the life cycle of all its components, then realize the process loading of the\n\nautomatic auxiliary module during the process initialization.\n\n3.2.2 Social software process execution\n\nThe process execution is completed by the application layer module and service layer\n\nmodule together. Sellers on a social network use automatic auxiliary modules to\n\ncomplete business activities, trigger information capture module to collect social infor-\n\nmation, and send it to the information collection service for subsequent processing.\n\n3.2.3 Local processing of social information\n\nThe local processing of social information is mainly completed by the information col-\n\nlection service. In order to ensure the safe storage and transmission of the collected so-\n\ncial information, the information collection service first adopts the encryption and\n\ncompression method to realize the local security cache and then adopts the HTTPS se-\n\ncure communication and transmission protocol to upload the data.\n\n3.2.4 Background processing of social information\n\nThe background processing of social information is completed by the background ser-\n\nver. The server first receives the social information uploaded by the intelligent space,\n\nnext decrypts and decompresses the social information, cleans the plaintext data, uses\n\nthird-party OCR technology to identify text information in images, and adds it to the\n\nuser’s social information after simple data processing. Then, the classification of sellers\n\non a social network is realized through the data based on machine learning modeling.\n\nFinally, the classification results are stored in the target database.\n\n4 Methods\nTo classify the business attributes of social e-commerce based on the information of\n\nsellers on a social network, traditional feature matching scheme and classification clus-\n\ntering scheme based on machine learning can be used to establish the model. In this\n\nchapter, we introduce the scheme based on term frequency-inverse document fre-\n\nquency (TF-IDF) clustering and the classification scheme based on BERT.\n\n4.1 Feature classification and TF-IDF clustering\n\n4.1.1 Feature classification\n\nWe randomly select 5000 sellers on a social network from the data collected by the\n\nbackground server and extracted the text data of their social information for analysis.\n\nEach social e-commerce user contains an average of 50 social text data. Based on the\n\ncontent, we manually classify social e-commerce into 11 categories. With the help of e-\n\ncommerce platforms like JD.COM, 50–100 keywords are sorted out for each category,\n\nand these keywords are screened and expanded according to the language habits of\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 6 of 12\n\n\n\nsellers on a social network. On this basis, we collect all the social information of each\n\nsocial network seller, cut and remove word segmentation, and match the results with\n\nthe keywords of the selected 11 categories. The number of keywords that are matched\n\nis counted as the matching degree. According to the situation of different classification,\n\nthe threshold of matching degree is determined by manual screening of some results,\n\nand then all social e-commerce is classified according to the threshold. After\n\noptimization and verification, the accuracy of the classical feature matching scheme fi-\n\nnally reached 40%. However, due to the simplicity of the rules of the feature matching\n\nscheme, the small optimization space, the high misjudgment rate of the scheme, and\n\nthe large human intervention in the basic word segmentation process, it is difficult to\n\ncover various situations of social e-commerce due to the limitation of these basic key-\n\nwords, thus making it insensitive to the dynamic changes of new hot words of social e-\n\ncommerce.\n\n4.1.2 TF-IDF clustering\n\nTo achieve the goal of accurate classification of social e-commerce, we designed a\n\nscheme based on TF-IDF clustering. Term frequency-inverse document frequency (TF-\n\nIDF) is a commonly used weighted technique for information retrieval and text mining\n\nto evaluate the importance of a single word to a document in a set of documents or a\n\ncorpus. In this scheme, the social information of each social e-commerce user is\n\nmapped as one file set of TF-IDF, and all texts of all sellers on a social network are\n\nmapped as the whole corpus. The words with the highest frequency used by each social\n\ne-commerce user are the most representative words in this document and become key-\n\nwords. Category labels can be generated to calculate the probability that a document\n\nbelongs to a certain category using the naive Bayes algorithm formula. The advantages\n\nof TF-IDF clustering to achieve the classification of sellers on the social network in-\n\nclude the following: (1) clear mapping; (2) emphasize the weight of keywords and lower\n\nthe weight of non-keywords; (3) compared with other machine learning algorithms, the\n\ncharacteristic dimension of the model is greatly reduced to avoid the dimension disas-\n\nter; and (4) while improving the efficiency of classification calculation, ensure that the\n\nclassification effect has a good accuracy and recall rate. The architecture of the entire\n\nsolution is shown in Fig. 3.\n\nIn the text preprocessing stage, the first thing to do is to format the social informa-\n\ntion, mainly including deleting the space, deleting the newline character, merging the\n\nsocial e-commerce text, and so on, and finally getting the text to be processed for word\n\nsegmentation. In this scheme, we choose Jieba’s simplified mode for word segmenta-\n\ntion, then filter out the noise by filtering the stop words (e.g., yes, ah, etc.).\n\nIn the stage of establishing the vector space model, the first step is to load the train-\n\ning set and take the pre-processed social information of each social e-commerce user\n\nas a document. The next step is to generate a dictionary, by adding every word that ap-\n\npears in the training set to it, using the complete dictionary to calculate the TF-IDF\n\nvalue of each document. In this scheme, CountVectorizer and TfidfTransformer in Py-\n\nthon’s Scikit-Learn library are used. CountVectorizer is used to convert words in the\n\ntext into word frequency matrix, TfidfTransformer is used to count the TF-IDF value\n\nof each word in each document, and the top20 words in each document are taken as\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 7 of 12\n\n\n\nkeywords of sellers on a social network. After this step, the keywords with a large TF-\n\nIDF value in each document are the most representative words in the document, which\n\nbecome the keyword set of the social e-commerce user. Finally, the naive Bayes method\n\nis used to generate the category label, and the document vectors belonging to the same\n\ncategory in the TF-IDF matrix are added to form a matrix of m*n, where m represents\n\nthe number of categories and n represents the number of documents. The weight of\n\neach word is divided by the total weight of all words of the class, to calculate the prob-\n\nability that a document belongs to a certain class.\n\nIn the model optimization stage, we optimize the whole scheme model by adjusting\n\nthe stop word set, adjusting parameters (including CountVectorizer, TfidfTransformer\n\nclass construction parameters), and adjusting the category label generation method.\n\nThe main idea of TFIDF is if a word or phrase appears in an article with a high fre-\n\nquency of TF, and rarely appears in other articles, it is considered that the word or\n\nphrase has a good classification ability and is suitable for classification. TFIDF is actu-\n\nally: TF * IDF, TF is term frequency and IDF is inverse document frequency.\n\nIn a given document, word frequency refers to the frequency of a given word in the\n\ndocument. This number is a normalization of the number of words to prevent it from\n\nbeing biased towards long documents. For the word ti in a particular document, its im-\n\nportance can be expressed as:\n\ntf i; j ¼\nj D j\n\nj j : ti∈d j\n� � j\n\namong them:\n\n|D|: The total number of files in the corpus\n\n∣{j : ti ∈ dj}∣: The number of documents containing the term ti (i.e., the number of\n\ndocuments in ni, j ≠ 0). If the term is not in the corpus, it will cause the dividend to be\n\nzero, so it is generally used 1 + ∣ {j : ti ∈ dj}∣.\n\nand then:\n\n Social e-\ncommerce data\n\nData preparation\n\nFormat processing\n\nFilter stop words\n\nText preprocessing\n\nGenerate directory\n\nBuild the vector space and \nTF-IDF\n\nGenerate category tags\n\nBayesian classifier\n\nText articiple\n\nLoad training set \n\nBuild tf matrix \n\nbuild vector\n\nbuild matrix \n\nConditional probability \nmatrix\n\nModel optimization\n\nFig. 3 TF-IDF scheme framework\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 8 of 12\n\n\n\ntfidf i; j ¼ tf i; j � idf i\n\nA high word frequency in a particular document and a low document frequency of\n\nthe word in the entire document collection can produce a high-weight TF-IDF. There-\n\nfore, TF-IDF tends to filter out common words and keep important words.\n\n4.2 Classification scheme based on BERT\n\n4.2.1 Data label\n\nWe manually classify and mark the data of sellers on a social network according to the\n\ncharacteristics of the products. Classified labels include 38,970 items and 17 categories\n\nof data, including 3c, dress, food, car, house, beauty, makeup, training, jewelry, promo-\n\ntion, medicine and health, phone charge recharge, finance, card category, cigarettes, es-\n\nsays, and others. The pre-processing phase removes emojis, numbers, and spaces from\n\nthe text through Unicode encoding.\n\n4.2.2 Classification scheme\n\nIn the BERT model, Transformer, as an encoder-decoder model based on attention\n\nmechanism, solves the problem that RNN cannot deal with long-distance dependence\n\nand the model cannot be parallel, improving the performance of the model without re-\n\nducing the accuracy. At the same time, BERT introduced the shading language model\n\n(MLM, masked language model) and context prediction method, further enhance the\n\ntwo-way training of the ability of feature extraction and text. MLM uses Transformer\n\nencoders and bilateral contexts to predict random masked tokens to pre-train two-way\n\ntransformers. This makes BERT different from the GPT model, which can only conduct\n\none-way training and can better extract context information through feature fusion.\n\nAnaphase prediction is more embodied in QA and NLI. Therefore, we choose the\n\nBERT model based on the bidirectional coding technology of pre-training and attention\n\nmechanism to classify sellers on a social network.\n\nWe chose the official Chinese pre-training model of Google as the pre-training model\n\nof the experiment: BERT-Base which is Chinese simplified and traditional, 12-layer,\n\n768-hidden, 12-head, 110M parameters [16]. This pre-training model is obtained by\n\nGoogle’s unsupervised pre-training on a large-scale Chinese corpus. On this basis, we\n\nwill carry out fine-tuning to realize the classification model of sellers on a social net-\n\nwork. When dividing the data set, we divided 38,970 pieces of data into training set\n\nand verification set according to the ratio of 6:4, that is, 23,382 pieces of training set\n\nand 15,588 pieces of verification set.\n\n5 Results and discussion\n5.1 TF-IDF clustering scheme\n\nThe computer used in the experiment is configured with AMD Ryzen R5-4600H CPU,\n\n16G memory, and windows10 64bit operating system. First, the default construction\n\nparameters are used, and the average accuracy of each classification is 45.7%. Next, the\n\nparameters are adjusted through a genetic algorithm, and 100 rounds of genetic algo-\n\nrithm optimization are performed, then the average accuracy reached the highest value\n\nof 52.5%. In the process of genetic algorithm, statistical estimation of algorithm time is\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 9 of 12\n\n\n\nalso carried out. On average, on this data set, the running time of each round of the\n\nTF-IDF model is about 28 s.\n\nExperiments show that the accuracy of the TF-IDF clustering scheme has been\n\nimproved after optimization, and it has a certain reference value for the classifica-\n\ntion of sellers on a social network, but there is still a big gap from the accurate\n\nclassification. We found three reasons after analyzing the experimental results. (1)\n\nCompared to the feature matching scheme, the TF-IDF-based model is improved\n\nto some extent. However, the input of the model is still the result of direct word\n\nsegmentation, and more information is lost in the word segmentation process, such\n\nas the semantic information of previous and later texts and the repetition fre-\n\nquency of corpus, which are relatively important in the process of natural language\n\nprocessing. (2) The classification problem of sellers on a social network is compli-\n\ncated. This model does not analyze the correlation between words and is essen-\n\ntially an upgraded version of word frequency statistics, which makes it difficult to\n\nimprove the accuracy after reaching a certain value. (3) For the optimization of the\n\nmodel, only the parameters of the intermediate function are adjusted, and the\n\nmethod is not upgraded. Therefore, the machine learning scheme based on TF-IDF\n\nclustering cannot solve the problem of accurate classification of sellers on a social\n\nnetwork. In the next chapter, we will introduce a scheme based on deep learning\n\nto achieve the goal of classifying sellers on a social network.\n\n5.2 Classification scheme based on BERT\n\nText classification fine-tuning is to serialize the preprocessed text information\n\ntoken and input BERT, and select the final hidden state of the first token [CLS] as\n\na sentence vector to output to the full connection layer, and then output the prob-\n\nability of obtaining various labels corresponding to the text through the softmax\n\nlayer. The experimental schematic diagram is shown in Figs. 4 and 5. The max-\n\nimum length of the sequence (ma_seq_length) is set to 256 according to the actual\n\ntext length of the social information data set of the sellers on a social network and\n\nFig. 4 Text message token serialization\n\nFig. 5 Text classification BERT fine-tuning model structure diagram\n\nCui et al. EURASIP Journal on Image and Video Processing          (2021) 2021:4 Page 10 of 12\n\n\n\nthe batch_size and learning rate adopt the official recommended values of 32 and\n\n2e−5. In addition, we also adjust the super parameter num_train_epochs and in-\n\ncrease the number of training epochs (num_train_epochs) from 3 to 9 to improve\n\nthe recognition rate of the model (Table 1). The results are shown in Table 2.\n\nWe select an additional 9500 text data of sellers on social networks and test the\n\nmodel after the same preprocessing. The accuracy rate is 90.5%, which is lower than\n\nthat of the verification set (96.2%). The reason may be that the data of the test set con-\n\ntains a large number of commodity terms not included in the corpus and training set,\n\nand the text description of these commodities is too colloquial. Sellers on a social net-\n\nwork often use colloquial words in the industry to replace the standard product names\n\nwhen releasing product information, such as “Bobo” instead of “Botox,” which to some\n\nextent limits the accuracy of text-based classification in the social e-commerce market\n\nscene.\n\n6 Conclusion\nThe classification model proposes in this paper achieves an accuracy of 90.5% in the\n\ntest data. However, there are still some problems such as non-standard description text.\n\nA corpus with a high correlation with a social e-commerce environment will be estab-\n\nlished in order to further improve the accuracy of social e-commerce classification. At\n\nthe same time, we will use the knowledge distillation technology to compress and refine\n\nthe existing model, so as to improve the model recognition rate while simplifying the\n\nmodel and improving the operational performance [16]. In addition, in view of the high\n\nlabor cost and time cost of large-scale data marking, the next step will be trying to\n\nmake full use of semi-s",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmRhdGEuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zMTM2NDAtMDIwLTAwNTQ1LXoucGRm0",
      "keyphrases": [
        "classification method",
        "social information",
        "social network",
        "sellers"
      ],
      "title": "A classification method for social information of sellers on social network",
      "author": "Haoliang Cui"
    },
    {
      "@search.score": 1.3259062,
      "content": "\nQER: a new feature selection method \nfor sentiment analysis\nTuba Parlar1* , Selma Ayşe Özel2 and Fei Song3\n\nIntroduction\n“What other people think” has always been an important piece of information for most \nof us during the decision making process [1]. The Internet and social media provide a \nmajor source of information about people’s opinions. Due to the rapidly-growing num-\nber of online documents, it becomes both time-consuming and hard to obtain and ana-\nlyze the desired opinionated information. Turkey is among the top 20 countries with the \nhighest numbers of Internet users according to the Internet World Stats.1 The exploding \ngrowth in the Internet users is one of the main reasons that sentiment analysis for differ-\nent languages and domains becomes an actively-studied area for many researchers \n[2–6].\n\nSentiment analysis (SA) is a natural language processing task that classifies the senti-\nments expressed in review documents as “positive” or “negative”. In general, SA is con-\nsidered as a two-class classification problem. However, some researchers use “neutral” as \n\n1 http://www.internetworldstats.com/.\n\nAbstract \n\nSentiment analysis is about the classification of sentiments expressed in review docu-\nments. In order to improve the classification accuracy, feature selection methods are \noften used to rank features so that non-informative and noisy features with low ranks \ncan be removed. In this study, we propose a new feature selection method, called \nquery expansion ranking, which is based on query expansion term weighting meth-\nods from the field of information retrieval. We compare our proposed method with \nother widely used feature selection methods, including Chi square, information gain, \ndocument frequency difference, and optimal orthogonal centroid, using four classi-\nfiers: naïve Bayes multinomial, support vector machines, maximum entropy model-\nling, and decision trees. We test them on movie and multiple kinds of product reviews \nfor both Turkish and English languages so that we can show their performances for \ndifferent domains, languages, and classifiers. We observe that our proposed method \nachieves consistently better performance than other feature selection methods, and \nquery expansion ranking, Chi square, information gain, document frequency difference \nmethods tend to produce better results for both the English and Turkish reviews when \ntested using naïve Bayes multinomial classifier.\n\nKeywords: Sentiment analysis, Feature selection, Machine learning, Text classification\n\nOpen Access\n\n© The Author(s) 2018. This article is distributed under the terms of the Creative Commons Attribution 4.0 International License \n(http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, \nprovided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and \nindicate if changes were made.\n\nRESEARCH\n\nParlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \nhttps://doi.org/10.1186/s13673-018-0135-8\n\n*Correspondence:   \ntparlar@mku.edu.tr \n1 Department \nof Mathematics, Mustafa \nKemal University, Antakya, \nHatay, Turkey\nFull list of author information \nis available at the end of the \narticle\n\nhttp://orcid.org/0000-0002-8004-6150\nhttp://www.internetworldstats.com/\nhttp://creativecommons.org/licenses/by/4.0/\nhttp://crossmark.crossref.org/dialog/?doi=10.1186/s13673-018-0135-8&domain=pdf\n\n\nPage 2 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nthe third class label. There are a number of studies about sentiment analysis that use dif-\nferent approaches for data preprocessing, feature selection, and sentiment classification \n[1, 3, 4, 6–10]. The statistical methods such as Chi square (CHI2) and information gain \n(IG) are used to eliminate unnecessary or irrelevant features so that the classification \nperformance can be improved [11]. Supervised learning methods including naïve Bayes \n(NB), support vector machines (SVM), decision trees (DT), and maximum entropy mod-\nelling (MEM) are used to classify the sentiments of the reviews.\n\nAlthough SA can be considered as a text classification task, it has some differences \nfrom the traditional topic-based text classification. For example, instead of saying: “This \ncamera is great. It takes great pictures. The LCD screen is great. I love this camera” in a \nreview document, people are more likely to write: “This camera is great. It takes breath-\ntaking pictures. The LCD screen is bright and clear. I love this camera.” [8]. As can be \nseen, sentiment-expressing words like “great” are not so frequent within a particular \nreview, but can be more frequent across different reviews, and a good feature selection \nmethod for SA should take this observation into account.\n\nIn this paper, we propose a new feature selection method, called query expansion rank-\ning (QER) which is especially developed for reducing dimensionality of feature space of \nSA problems. The aim of this study is to show that our proposed method is effective for \nSA from review texts written in different languages (e.g., Turkish, English) and domains \n(e.g., movie reviews, book reviews, kitchen appliances reviews, etc.). QER is based on \nquery expansion term weighting methods used to improve the search performance of \ninformation retrieval systems [12, 13] and to evaluate its effectiveness as a feature selec-\ntor in SA, we compare it with other common feature selection methods, including CHI2, \nIG, document frequency difference (DFD), and optimal orthogonal centroid (OCFS), \nalong with four text classifiers: naïve Bayes multinomial (NBM), SVM, DT, and MEM, \nover ten different review documents datasets. Our goal is to examine whether these fea-\nture selection methods can reduce the feature sizes and improve the classification accu-\nracy of sentiment analysis with respect to different document domains, languages, and \nclassifiers.\n\nThe rest of the paper is organized as follows. “Related work” reviews the related work \non sentiment analysis. “Methods” presents the methods that we used for our study, \nincluding the new feature selection method we proposed. “Experiments and results” \ndescribes the experimental settings, datasets, performance measures, and testing results. \nFinally, “Conclusion” concludes the paper.\n\nRelated work\nSA is an important topic in Natural Language Processing and Artificial Intelligence. \nAlso known as opinion mining, SA mines people’s opinions, sentiments, evalua-\ntions, and emotions about entities such as products, services, organizations, individu-\nals, issues, and events, as well as their related attributes. This kind of analysis has many \nuseful applications. For example, it determines a product’s popularity according to \nthe user’s reviews. If the overall sentiments are negative, further analysis may be per-\nformed to identify which features contribute to the negative ratings so companies can \nreshape their businesses. Numerous studies have been done for sentiment analysis in \ndifferent domains, languages, and approaches [3–5, 8–10, 14–17]. Among these studies, \n\n\n\nPage 3 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nthe machine learning approaches are more popular since the models can be automati-\ncally trained and improved with the training datasets. Pang et al. [4] apply supervised \nmachine learning methods such as NB and SVM to sentiment classification. NB, SVM, \nMEM, and DT are some of the commonly used machine learning approaches [4, 7–9, \n14]. Feature selection methods are used to rank features so that non-informative features \ncan be removed to improve the classification performance [18]. Some researchers have \ninvestigated the effects of feature selection for sentiment analysis [3, 8–10, 19–25]. For \nexample, Yang and Yu [3] examine IG for feature selection and evaluate its performance \nusing NB, SVM, and C4.5 (popular implementation for DT) classifiers. Nicholls et al. [8] \ncompare their proposed DFD feature selection method against other feature selection \nmethods, including CHI2, OCFS [26], and count difference using the MEM classifier. \nAgarwal et al. [9] investigate minimum redundancy maximum relevancy (mRMR) and \nIG methods for sentiment classification using NBM and SVM classifiers. The results \nshow that mRMR performs better than IG for feature selection, and NBM performs bet-\nter than SVM in accuracy and execution time. Abbasi et al. [22] examine a new feature \nselection method called entropy weighted genetic algorithm (EWGA) and compare the \nperformance of this method using information gain feature selection method. EWGA \nachieves a relatively high accuracy of 91.7% using SVM classifier. Xia et al. [24] design \ntwo types of feature sets: POS based and word relation based. Their word relation based \nmethod improves an accuracy of 87.7 and 85.15% on movie and product datasets. Bai \n[25] proposes a Tabu heuristic search-enhanced Markov blanket model that provides a \nvocabulary to extract sentiment features. Their method achieves an accuracy of 92.7% \nfor the movie review dataset. Mladenovic et al. [16] propose a feature selection method \nthat is based on mapping of a large number of related features to a few features. Their \nproposed method improves the classification performance using unigram features \nwith 95% average accuracy. Zheng et al. [27] perform comparative experiments to test \ntheir proposed improved document frequency feature selection method. Their method \nachieves significant improvement in sentiment analysis of Chinese online reviews with \nan accuracy of 97.3%.\n\nMost of the SA studies listed above focus on the English language. Only few studies \nhave been done on SA for the Turkish language [6, 10, 19, 28–31]. The Turkish language \nbelongs to the Altaic branch of the Ural-Altaic family of languages and is mainly used in \nthe Republic of Turkey. Turkish is an agglutinative language similar to Finnish and Hun-\ngarian, where a single word can be translated into a relatively longer sentence in English \n[32]. For instance, word “karşılaştırmalısın” in Turkish can be expressed as “you must \nmake (something) compare” in English. As Turkish and English have different charac-\nteristics, methods developed for SA in English need to be tested for Turkish. Among \nthe few researchers who investigate the effects of feature selection on the SA of Turkish \nreviews, Boynukalın [29] applies Weighted Log Likelihood Ratio (WLLR) to reduce fea-\nture space with NB, Complementary NB, and SVM classifiers for the emotional analysis \nusing the combinations of n-grams where sequences of n words are considered together. \nIt is shown that WLLR helps to improve the accuracy with reduced feature sizes. Akba \net al. [19] implement and compare the performance of reduced feature sizes using two \nfeature selection methods: CHI2 and IG with NB and SVM classifiers. They show that \nfeature selection methods improve the classification accuracy.\n\n\n\nPage 4 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nOur aim is to propose a new feature selection method for the SA of Turkish and Eng-\nlish reviews. We presented an initial version of this method in [10] where we employ \nonly product review dataset in Turkish and compare our method with CHI2 and DFD \nby using only one classifier. We now extend it to more datasets for Turkish, and also \ninvestigate the performance of our method in English datasets to show that our method \nis language independent. We further include more feature selection methods especially \ndeveloped for SA and compare the performance of our proposed method using NBM, \nSVM, MEM, and DT classifiers along with statistical analysis to prove that our method is \nclassifier independent.\n\nMethods\nMachine learning algorithms\n\nFor sentiment classification, we use the Weka [33] data mining tool, which contains the \nfour classifiers we use in our experiments, i.e., NBM, SMO for SVM, J48 for C4.5, and LR \nfor MEM. We choose NBM, SVM, LR, and J48 classification methods due to the follow-\ning reasons: (i) many researchers use NBM for text classification because it is computa-\ntionally efficient [9, 10, 14] and performs well for large vocabulary sizes [34]; (ii) SVM \ntends to perform well for traditional text classification tasks [3, 4, 7, 14, 35]; (iii) LR is \nknown to be equivalent to MEM which is another method used in SA studies [8]; (iv) J48 \nis a well-known decision tree classifier for many classification problems and is used for \nSA [3, 30].\n\nFeature selection\n\nFeature Selection methods have been shown to be useful for text classification in general \nand sentiment analysis in specific [11, 18]. Such methods rank features according to cer-\ntain measures so that non-informative features can be removed, and at the same time, \nthe most valuable features can be kept in order to improve the classification accuracy \nand efficiency. In this study, we consider several feature selection methods, including \ninformation gain, Chi square, document frequency difference, optimal orthogonal cen-\ntroid, and our new query expansion ranking (QER) so that we can compare their effec-\ntiveness for the sentiment analysis.\n\nFeature sizes are selected in the range from 500 to 3000 with 500 increments, com-\npared with the total feature sizes ranging from 8000 to 18,000 for the Turkish review \ndatasets and from 8000 to 38,000 for English review datasets. In our previous study [10], \nwe observed that feature sizes up to 3000 tend to give good classification performance \nimprovement; therefore we choose these feature sizes in our experiments.\n\nInformation gain\n\nInformation gain is one of the most common feature selection methods for sentiment \nanalysis [3, 9, 19, 35], which measures the content of information obtained after knowing \nthe value of a feature in a document. The higher the information gain, the more power \nwe have to discriminate between different classes.\n\nThe content of information can be calculated by the entropy that captures the uncer-\ntainty of a probability distribution for the given classes. Given m number of classes: \nC = {c1,c2,…,cm} the entropy can be given as follows:\n\n\n\nPage 5 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nwhere P(ci) is the probability of how many documents in class ci. If an attribute A has n \ndistinct values: A = {a1,a2,…,an}, then the entropy after the attribute A is observed can be \ndefined as follows:\n\nwhere P(aj) is the probability of how many documents contain the attribute value aj, and \nP(ci|aj) is the probability of how many documents in class ci that contain the attribute \nvalue aj. Based on the definitions above, the information gain for an attribute is simply \nthe difference between the entropy values before and after the attribute is observed:\n\nFor sentiment analysis, we normally classify the reviews into positive and negative cat-\negories, and for each keyword, it either occurs or does not occur in a given document; so \nthe above formulas can be further simplified. Nevertheless, we can cut down the number \nof features in the same way by choosing the keywords that have high information gain \nscores.\n\nChi square (CHI2)\n\nChi square measures the dependence between a feature and a class. A higher score \nimplies that the related class is more dependent on the given feature. Thus, a feature with \na low score is less informative and should be removed [3, 8, 10, 19]. Using the 2-by-2 \ncontingency table for feature f and class c, where A is the number of documents in class c \nthat contains feature f, B is the number of documents in the other class that contains f, C \nis the number of documents in c that does not contain f, D is the number of documents \nin the other class that does not contain f, and N is the total number of documents, then \nthe Chi square score can be defined in the following:\n\nThe Chi square statistics can also be computed between a feature and a class in the \ndataset, which are then combined across all classes to get the scores for each feature as \nfollows:\n\nOne problem with the CHI2 method is that it may produce high scores for rare features \nas long as they are mostly used for one specific class. This is a bit counter-intuitive, since \nrare features are not frequently used in text and thus do not have a big impact for text \n\n(1)H(C) = −\n\nm\n∑\n\ni=1\n\nP(ci) log2 P(ci)\n\n(2)H(C|A) =\n\nn\n∑\n\nj=1\n\n(\n\n−P(aj)\n\nm\n∑\n\ni=1\n\nP(ci|aj) log2P(ci|aj)\n\n)\n\n(3)IG(A) = H(C)−H(C|A)\n\n(4)χ2\n(\n\nf , c\n)\n\n=\nN (AD − CB)2\n\n(A+ C)(B+ D)(A+ B)(C + D)\n\n(5)χ2(f ) =\n\nm\n∑\n\ni=1\n\nP(ci)χ\n2(f , ci)\n\n\n\nPage 6 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nclassification. For SA, however, this is not a big issue since many sentiment-expressing \nfeatures are not frequently used within an individual review.\n\nDocument frequency difference\n\nInspired by the observation that sentiment-expressing words tends to be less frequent \nwithin a review, but more frequent across different reviews, Nicholls and Song [8] pro-\npose the DFD method that tries to differentiate the features for positive and negative \nclasses, respectively, across a document collection. More specifically, DFD is calculated \nas follows:\n\nwhere DFf\n+ is the number of documents in the positive class that contain feature f, DFf\n\n− \nis the number of documents in the negative class that contain f, and N is the total num-\nber of documents in the dataset. Note that all scores are normalized between 0 and 1; \nso they should be proportional for us to rank the features in a document collection. For \nexample, a non-sentiment word may have similar document frequencies in both posi-\ntive and negative classes, and will get a low score, but a sentiment word for the positive \nclass may have a bigger difference, resulting in a higher score. One limitation of the DFD \nmethod is that it requires an equal or nearly equal number of documents in both classes, \nwhich is more or less true for the datasets used in our experiments.\n\nOptimal orthogonal centroid (OCFS)\n\nOCFS method is an optimized form of the orthogonal centroid algorithm [26]. Docu-\nments are represented as high dimensional vectors where the weights of each dimension \ncorrespond to the importance of the related features, and a centroid is simply the aver-\nage vector for a set of document vectors. OCFS aims at finding a subset of features that \ncan make the sum of distances between all the class means maximized in the selected \nsubspace. The score of a feature f by OCFS is defined in the following [8]:\n\nwhere Nc is the number of documents in class c, N is the number of documents in the \ndataset, mc is the centroid for class c, m is the centroid for the dataset D, and mf, mc\n\nf are \nthe values of feature f in centroid m, mc respectively. The centroids of m and mc are cal-\nculated as follows:\n\nQuery expansion ranking\n\nQuery expansion ranking method is our proposed feature selection method inspired \nby the query expansion methods from the field of information retrieval (IR). Query \n\n(6)Scoref =\n|DF\n\nf\n+ − DF\n\nf\n−|\n\nN\n\n(7)Scoref =\n∑\n\nc\n\nNc\n\nN\n\n(\n\nm\nf\nc −mf\n\n)2\n\n(8)mc =\n\n∑\n\nxi∈c\nxi\n\nNc\n\n(9)m =\n\n∑\n\nxi∈D\nxi\n\nN\n\n\n\nPage 7 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nexpansion helps to find more relevant documents for a given query. It does so by adding \nnew terms to the query. The new terms are selected from documents that are relevant \nto the original query so that the expanded query can retrieve more relevant documents. \nMore specifically, terms from the relevant documents are extracted along with some \nscores, and those with the highest scores are included in the expanded query.\n\nWe propose a new feature selection method inspired by the query expansion technique \ndeveloped for probabilistic weighting model proposed by Harman [12]. Harman [12, 36] \nstudies how to assign scores to terms extracted from relevant documents for a given \nquery Q so that high scored terms are used to expand the original query and improve \nprecision of information retrieval strategy. In this method, first, query Q is sent to the \ninformation retrieval system, and then the system returns documents that are found as \nrelevant to the user. Then, user examines the returned documents and marks the ones \nthat are relevant with the query. After that, all the terms in the relevant documents are \nextracted and they are assigned scores by using a score formula as proposed by Har-\nman [12], and top scored k terms are chosen as the most valuable terms to expand the \nquery. Then, the expanded query Q’, which includes the terms in the original query plus \nthe k new terms that have the top-k scores, is sent to the information retrieval system to \nreturn more relevant documents to the original query Q. Equation 10 presents the score \nformula developed by Harman [12] to calculate ranking score of a term f extracted from \nthe set of relevant documents for a given query Q.\n\nwhere pf is the probability of term f in the set of relevant documents for query Q, and qf \nis the probability of term f in the set of non-relevant documents for query Q. These prob-\nability scores are computed according to Robertson and Sparck Jones [13].\n\nWe revise the above score computation method to develop an efficient feature selector \nfor SA. In our feature selection method, we propose a score formula given in Eq. 11 to \ncompute scores for features:\n\nwhere pf is the ratio of positive documents containing feature f and qf is the ratio of \nnegative documents containing feature f, which are computed according to Eqs. 12, 13, \nrespectively:\n\n(10)Scoref = log2\npf\n(\n\n1− qf\n)\n\n(\n\n1− pf\n)\n\nqf\n\n(11)Scoref =\npf + qf\n∣\n\n∣pf − qf\n∣\n\n∣\n\n(12)pf =\nDF\n\nf\n+ + 0.5\n\nN+ + 1.0\n\n(13)qf =\nDF\n\nf\n− + 0.5\n\nN− + 0.5\n\n\n\nPage 8 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nwhere DFf\n+ and DFf\n\n− are the raw counts of documents that contain f in the positive and \nnegative classes, respectively and N+ and N− are the numbers of documents in the \npositive and negative classes, respectively. In the probability calculations, we add small \nconstants to the numerators and denominators in Eqs. 12, 13 following Robertson and \nSparck Jones [13] who add similar constants to avoid having zero probabilities. Such a \nmethod is known as data smoothing in statistical language processing.\n\nIn QER feature selection method, scores of features are computed before the features \nhaving the lowest scores are selected and used in the classification process. When a fea-\nture has low score, the difference between the probabilities for the positive and negative \nclasses is high; therefore the feature is more class specific and more valuable for clas-\nsification process. Among the feature selection methods we considered, we notice that \nIG and OCFS are good at distinguishing multiple classes, while CHI2, DFD, and QER \nare restricted to two classes, although all of them are suitable for sentiment analysis. IG \nis considered as a greedy approach since it favors those that can maximize the informa-\ntion gain for separating the related classes. Although CHI2 tries to identify the features \nthat are dependent to a class, it can also give high values to rare features that only affect \nfew documents in a given collection. OCFS has been shown to be effective for tradi-\ntional topic-based text classification, but it depends on the distance/similarity measures \nbetween the vectors of the related documents. Since sentiment-expressing features do \nnot happen frequently within a review, as illustrated by the example in the introduction, \nthey may not be favored by the OCFS method. QER is similar to DFD in that they both \nrely on the differences of the document frequencies of a given feature between the two \nclasses. However, QER is different from DFD in that it normalizes the document fre-\nquencies of a feature in both classes into probabilities and uses the ratio of the sum over \nthe difference for these two probabilities.\n\nExperiments and results\nDatasets\n\nWe use Turkish and English review datasets in our experiments. The Turkish movie \nreviews are collected from a publicly available website (http://www.beyazperde.com) \n[30]. The dataset has 1057 positive and 978 negative reviews. The Turkish product review \ndataset is collected from an e-commerce website (http://www.hepsiburada.com) from \ndifferent domains [28]. It consists of four subsets of reviews about books, DVDs, elec-\ntronics, and kitchen appliances, each of which has 700 positive and 700 negative reviews. \nTo compare our results with existing work for sentiment analysis, we use similar datasets \nfor English reviews. The English movie review dataset is introduced by Pang and Lee [7], \nand consists of 1000 positive and 1000 negative reviews. English product review dataset \nis introduced by Blitzer et al. [37] and also has four subsets: books, DVDs, electronics, \nand kitchen appliances, with 1000 positive and 1000 negative reviews for each subset. In \norder to keep the same dataset sizes with Turkish product reviews, we randomly select \n700 positive and 700 negative reviews from each subset of the English product reviews.\n\nPerformance evaluation\n\nThe performance of a classification system is typically evaluated by F measure, which \nis a composite score of precision and recall. Precision (P) is the number of correctly \n\nhttp://www.beyazperde.com\nhttp://www.hepsiburada.com\n\n\nPage 9 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nclassified items over the total number of classified items with respect to a class. Recall \n(R) is the number of correctly classified items over the total number of items that belong \nto a given class. Together, the F measure gives the harmonic mean of precision and \nrecall, and is calculated as follows [33]:\n\nSince we are doing multi-fold cross validations in our experiments, we use the micro-\naverage of F measure for the final classification results. This is done by adding the clas-\nsification results for all documents across all five folds before computing the final P, R, \nand the F.\n\nExperimental settings\n\nWe conduct the experiments on a MacBook Pro with 2.5 GHz Intel Core i7 processor \nand 16 GB 1600 MHz DDR3. We use Python with NLTK [38] library in our experiments. \nAfter tokenizing text into words along with case normalization, we keep some punctua-\ntion marks and stop words, as they may express sentiments (e.g., punctuation marks like \nexclamation and question marks, and stop words like “too” in “too expensive”). In addi-\ntion, we do not apply stemming as Turkish is an agglutinative language and the polarity \nof a word is often included in the suffixes. Therefore, we can have a large feature space \nand it becomes important to apply feature selection methods to reduce this space. For \nsentiment classification, we use the Weka [33] data mining tool, which contains the four \nclassifiers we use in our experiments, i.e., NBM, SMO for SVM, J48 for C4.5, and LR for \nMEM. Since our datasets are relatively small with at most a couple of thousands of docu-\nments, we apply the fivefold cross validation, which divides a dataset into five portions: \nfour of them are used for training and the remaining one for testing, and then these por-\ntions are rotated to get a total of five F measures. Table 1 the average F measures for all \nthe classifiers where the whole feature spaces are used for each dataset, except the LR \nclassifier since it requires too much memory to handle the whole feature spaces for these \ndatasets. As can be seen in Table  1, the total number of features without any reduc-\ntion ranges from 9000 to 18,000 for the Turkish review datasets, and 8,000–38,000 for \nthe English review datasets. These results form the baselines of our study and any new \nresults obtained with feature selection methods by applying five folds cross validation \ncan be compared for possible improvements.\n\n(14)F = 2×\nP × R\n\nP + R\n\nTable 1 Baseline results in F measure for the Turkish and English review datasets\n\nTurkish review datasets English review datasets\n\nFeatures NBM SVM J48 LR Features NBM SVM J48 LR\n\nMovie 18,578 0.8248 0.8161 0.6954 – 38,869 0.8129 0.8480 0.6769 –\n\nDVDs 11,343 0.7957 0.7320 0.6886 – 17,674 0.7836 0.7649 0.6789 –\n\nElectronics 10,911 0.8155 0.7707 0.7371 – 9010 0.7629 0.7856 0.6750 –\n\nBook 10,511 0.8317 0.7955 0.7019 – 18,306 0.7619 0.7485 0.6407 –\n\nKitchen 9447 0.7762 0.7407 0.6647 – 8076 0.8099 0.8136 0.7093 –\n\n\n\nPage 10 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nPerformance of feature selection methods for Turkish reviews\n\nWe tested five feature selection methods: QER, CHI2, IG, DFD, and OCFS on both \nTurkish and English review datasets. For each feature selection method, we tried six fea-\nture sizes at 500, 1000, 1500, 2000, 2500, and 3000, since this is the range typically con-\nsidered for text classification, and in terms of total features, we have 9000–18,000 for the \nTurkish review datasets, and 8000–38,000 for English review datasets from our baseline \nsystems. In our previous study [10], we also observed that feature sizes up to 3000 tend \nto give good classification performance. For all feature selection methods, we pick the \ntop-ranked features of a desirable size n based on the scores of the related formulas for \nthese methods. All of these settings are run against four classifiers: NBM, SVM, LR, and \nJ48, resulting in a total of 120 experiments for each review dataset. Table 2 summarizes \nthe best results for all pairs of feature selection methods and Turkish review datasets. \nFor each pair, we show the best micro-average F measure along with the correspond-\ning classifier and feature size. Also, the best results for each review dataset are given in \nbold-face.\n\nAs observed in Table 2, our new method QER is the best performer for each review \ndataset. CHI2 and IG have almost the same performance for the Turkish reviews and \nhave better results than DFD and OCFS for the movie, book, DVDs, and kitchen review \ndatasets. DFD with NBM classifier has better results than CHI2, IG, and OCFS for the \nelectronics review dataset. Also, CHI2, IG, and QER tend to work well with smaller fea-\nture sizes, while DFD and OCFS tend to favour bigger feature sizes. Note that DFD does \nreasonably well across all review datasets, which confirms our intuition that sentiment-\nexpressing words usually have low frequencies within a document, but relatively high \nfrequencies across different documents. Although OCFS is quite robust for traditional \ntopical text classification as reported in Cai and Song [39], it is not doing well for senti-\nment analysis, perhaps for the same intuition as we just explained for DFD. Once again, \nNBM remains to be the best for most of our experiments except that SVM does the best \nfor the kitchen reviews when analysed with the CHI2 and IG methods. When analysed \nby univariate ANOVA and post hoc tests for the book, DVDs, electronics, and kitchen \nreview datasets, we found that there are significant differences between three groups \n(Baseline and OCFS), (DFD, CHI2, and IG) and (QER) at 95% confidence level. Within \neach group, however, there are no significant differences. For the movie review dataset, \nthere are significant differences between two groups (Baseline and OCFS), and (DFD, \nCHI2, IG, and QER) at the 95% confidence level. Overall, feature selection methods are \nshown to be effective for sentiment analysis, improving significantly over the baseline \nresults.\n\nTo examine the effects of text classifiers, we show the best classification results for \npairs of feature selection methods and text classifiers on the electronic review dataset in \nTable 3. Note that NBM does the best for all review datasets; J48 the worst; and SVM and \nLR in between, although LR is consistently better than SVM except for the QER method. \nOne reason that the decision-tree-based solution J48 does not do well for text classifi-\ncation in general [40] and sentiment analysis in specific is that it is a greedy approach, \nalways trying to find the features that separate the given classes the most. As a result, the \nclassifier may use a much smaller set of features, even though there are many more rel-\nevant features are available. SVM typically does well for the traditional topic-based text \n\n\n\nPage 11 of 19Parlar et al. Hum. Cent. Comput. Inf. Sci.  (2018) 8:10 \n\nTa\nb\n\nle\n 2\n\n T\nh\n\ne \nb\n\nes\nt c\n\nla\nss\n\nifi\nca\n\nti\no\n\nn\n r\n\nes\nu\n\nlt\ns \n\nfo\nr \n\np\nai\n\nrs\n o\n\nf f\nea\n\ntu\nre\n\n s\nel\n\nec\nti\n\no\nn\n\n m\net\n\nh\no\n\nd\ns \n\nan\nd\n\n th\ne \n\nTu\nrk\n\nis\nh\n\n r\nev\n\nie\nw\n\n d\nat\n\nas\net\n\ns\n\nQ\nER\n\nD\nFD\n\nO\nC\n\nFS\nC\n\nH\nI2\n\nIG\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\nSi\n\nze\nF \n\nm\nea\n\nsu\nre\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\nSi\n\nze\nF \n\nm\nea\n\nsu\nre\n\nSi\nze\n\nF \nm\n\nea\nsu\n\nre\n\nM\no",
      "metadata_storage_path": "aHR0cHM6Ly9jb3Jwb3JhdGV0cmFpbmRhdGEuYmxvYi5jb3JlLndpbmRvd3MubmV0L3BhcGVycy9zMTM2NzMtMDE4LTAxMzUtOC5wZGY1",
      "keyphrases": [
        "new feature selection method",
        "sentiment analysis",
        "QER"
      ],
      "title": "QER: a new feature selection method for sentiment analysis",
      "author": "Tuba Parlar "
    }
  ]
}
```
